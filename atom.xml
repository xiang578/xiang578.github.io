<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>算法花园</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xiang578.com/"/>
  <updated>2019-12-02T02:24:36.172Z</updated>
  <id>https://xiang578.com/</id>
  
  <author>
    <name>RyenX</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>强化学习基础知识</title>
    <link href="https://xiang578.com/post/reinforce-learnning-basic.html"/>
    <id>https://xiang578.com/post/reinforce-learnning-basic.html</id>
    <published>2019-11-21T12:50:36.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<p>这篇博文是李弘毅教授深度强化学习课程相关笔记。</p><p>课件下载：<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html" target="_blank" rel="noopener">Hung-yi Lee - Deep Reinforcement Learning</a></p><p>课程视频：<a href="https://www.youtube.com/watch?v=z95ZYgPgXOY&amp;list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_" target="_blank" rel="noopener">DRL Lecture 1: Policy Gradient (Review) - YouTube</a></p><h2 id="rl-基础">RL 基础</h2><p>强化学习基本定义：</p><ul><li>Actor：可以感知环境中的状态，通过执行不同的动作得到反馈的奖励，在此基础上进行学习优化。</li><li>Environment：指除 Actor 之外的所有事务，受 Actor 动作影响而改变其状态，并给 Actor 对应的奖励。</li></ul><p>一些符号：</p><ul><li>State s 是对环境的描述，其状态空间是 S。</li><li>Action a 是 Actore 的行为描述，其动作空间是 A。</li><li>Policy <span class="math inline">\(\pi(a|s)=P[A_t=a|S_t=s]\)</span> 代表在给定环境状态 s 下 动作 a 的分布。</li><li>Reward <span class="math inline">\({r(s,a,s^{\prime})}\)</span> 在状态 s 下执行动作 a 后，Env 给出的打分。</li></ul><h2 id="policy-gradient">Policy Gradient</h2><p>Policy Network 最后输出的是概率。</p><p>目标：调整 actor 中神经网络 policy <span class="math inline">\(\pi(\theta)\)</span>，得到 <span class="math inline">\(a=\pi(s, \theta)\)</span>，最大化 reward。</p><p>trajectory <span class="math inline">\(\tau\)</span> 由一系列的状态和动作组成，出现这种组合的概率是 <span class="math inline">\(p_{\theta}(\tau)\)</span> 。</p><p><span class="math display">\[\begin{array}{l}{p_{\theta}(\tau)} \\ {\quad=p\left(s_{1}\right) p_{\theta}\left(a_{1} | s_{1}\right) p\left(s_{2} | s_{1}, a_{1}\right) p_{\theta}\left(a_{2} | s_{2}\right) p\left(s_{3} | s_{2}, a_{2}\right) \cdots} \\ {\quad=p\left(s_{1}\right) \prod_{l=1}^{T} p_{\theta}\left(a_{t} | s_{t}\right) p\left(s_{t+1} | s_{t}, a_{t}\right)}\end{array}\]</span></p><p>reward ：根据 s 和 a 计算得分 r，求和得到 R。在围棋等部分任务中，无法获得中间的 r（下完完整的一盘棋后能得到输赢的结果）。</p><p>需要计算 R 的期望 <span class="math inline">\(\bar{R}_{\theta}\)</span>，形式和 GAN 类似。如果一个动作得到 reward 多，那么就增大这个动作出现的概率。最终达到 agent 所做 policy 的 reward 一直都比较高。</p><p><span class="math display">\[\bar{R}_{\theta}=\sum_{\tau} R(\tau) p_{\theta}(\tau)\]</span></p><p>强化学习中，没有 label。需要从环境中采样得到 <span class="math inline">\(\tau\)</span> 和 R，根据下面的公式去优化 agent。相当于去求一个 likelihood。</p><p><span class="math inline">\(\nabla f(x) = f(x) \frac{\nabla f(x)}{f(x)}= f(x) \nabla \log f(x)\)</span> ，这一步中用到对 log 函数进行链式求导。</p><p><span class="math display">\[\nabla \bar{R}_{\theta}=\sum_{\tau} R(\tau) \nabla p_{\theta}(\tau)\]</span></p><p><span class="math display">\[\begin{array}{l}{=E_{\left.\tau \sim p_{\theta}(\tau)[R(\tau)] \log p_{\theta}(\tau)\right]} \approx \frac{1}{N} \sum_{n=1}^{N} R\left(\tau^{n}\right) \nabla \log p_{\theta}\left(\tau^{n}\right)} \\ {=\frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}} R\left(\tau^{n}\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)}\end{array}\]</span></p><p>参数更新方法： 1. 在环境中进行采样，得到一系列的轨迹和回报。 2. 利用状态求梯度，更新模型。如果 R 为正，增大概率 <span class="math inline">\(p_{\theta}(a_t|s_t)\)</span>, 否则减少概率。 3. 重复上面的流程。</p><p><img src="/file/15726799935625.jpg"></p><h3 id="pg-的例子">PG 的例子</h3><p>训练 actor 的过程看成是分类任务：输入 state ，输出 action。</p><p>最下面公式分别是反向传播梯度计算和 PG 的反向梯度计算，PG 中要乘以整个轨迹的 R。</p><figure><img src="/file/15752505145081.jpg" alt="-w914"><figcaption>-w914</figcaption></figure><p>tip 1： add a baseline</p><p>强化学习的优化和样本质量有关，避免采样不充分。Reawrd 函数变成 R-b，代表回报小于 b 的都被我们当成负样本，这样模型能去学习得分更高的动作。b 一般可以使用 R 的均值。</p><p>tip 2: assign suitable credit</p><p>一场游戏中，不论动作好坏，总会乘上相同的权重 R，这种方法是不合理的，希望每个 action 的权重不同。</p><ol type="1"><li>引入一个 discount rate，对 t 之后的动作 r 进行降权重。</li><li>利用 Advantage Function 评价状态 s 下动作 a 的好坏 critic。</li></ol><figure><img src="/file/15752505547153.jpg" alt="-w844"><figcaption>-w844</figcaption></figure><h2 id="ppo">PPO</h2><h2 id="q-learning">Q-Learning</h2><h2 id="actor-critic">Actor Critic</h2><h2 id="sparse-reward">Sparse Reward</h2><h2 id="imitation-learning">Imitation Learning</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这篇博文是李弘毅教授深度强化学习课程相关笔记。&lt;/p&gt;
&lt;p&gt;课件下载：&lt;a href=&quot;http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hung
      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="algorithm" scheme="https://xiang578.com/tags/algorithm/"/>
    
      <category term="reinforcementlearning" scheme="https://xiang578.com/tags/reinforcementlearning/"/>
    
  </entry>
  
  <entry>
    <title>算法花园风格清单</title>
    <link href="https://xiang578.com/post/blog-writing-checklist.html"/>
    <id>https://xiang578.com/post/blog-writing-checklist.html</id>
    <published>2019-11-03T10:03:23.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>李如一在 <a href="https://www.qdaily.com/articles/1397.html" target="_blank" rel="noopener">写作风格手册</a> 中提到写作风格的作用是 「保持机构和组织内部的文体统一，提高沟通效率。」</p><p>本清单会持续更新，如果有相关的建议，可以在留言中告诉我。</p></blockquote><p>算法花园定位为个人博客，也是我和这个世界沟通的窗口。为提高读者阅读体验，参考相关文章后，推出该清单统一网站文章的基础风格。</p><h2 id="写作">写作</h2><ol type="1"><li>减少形容词使用，尽可能删除 「的」和「了」。</li><li>给出引用图片及引文来源。</li><li>文章如果发布后大幅度修改，在末尾给出版本信息。</li><li>写完文章后，整体阅读一遍。</li></ol><h2 id="排版">排版</h2><ol type="1"><li>中文、英文、数字中间加空格，数字与单位之间无需增加空格，全角标点与其他字符之间不加空格。链接前后增加空格用以区分。</li><li>不重复使用标点符号。</li><li>体中文中使用直角引号 「」以及『 』。</li><li>使用全角中文标点，数字使用半角字符。中文中出现英文部分，仍然使用中文标点。</li><li>遇到完整的英文整句、特殊名词，其內容使用半角标点。</li><li>专有名词使用正确的大小写，使用公认的缩写。</li><li>todo 如何处理图片排版和命名。</li><li>使用英文命名文档，使用 <code>-</code> 来连接。为保证搜索引擎效果，尽量不要修改文档名称。</li><li>发布后，在网页中确认格式是否符合预期、链接能否点击以及图片能否展示。</li></ol><h2 id="版本">版本</h2><blockquote><p>20191103: 第一版</p></blockquote><h2 id="参考">参考</h2><ul><li><a href="https://www.qdaily.com/articles/1397.html" target="_blank" rel="noopener">写作风格手册_设计词典_好奇心日报</a></li><li><a href="https://mazhuang.org/wiki/chinese-copywriting-guidelines/" target="_blank" rel="noopener">中文文案排版指北（简体中文版） — 码志</a></li><li><a href="https://zhuanlan.zhihu.com/p/49729668" target="_blank" rel="noopener">简体中文文本排版指南 - 知乎</a></li><li><a href="https://sspai.com/post/37815" target="_blank" rel="noopener">少数派写作排版指南 - 少数派</a></li><li><a href="https://www.jianshu.com/p/8ffc3e0d11e2" target="_blank" rel="noopener">城堡制作检查清单 0.1 版 - 简书</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;李如一在 &lt;a href=&quot;https://www.qdaily.com/articles/1397.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;写作风格手册&lt;/a&gt; 中提到写作风格的作用是 「保持机构和组织内部的文体
      
    
    </summary>
    
      <category term="站务" scheme="https://xiang578.com/categories/%E7%AB%99%E5%8A%A1/"/>
    
    
      <category term="blog" scheme="https://xiang578.com/tags/blog/"/>
    
      <category term="writing" scheme="https://xiang578.com/tags/writing/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统 CTR Paper 阅读小结</title>
    <link href="https://xiang578.com/post/ctr.html"/>
    <id>https://xiang578.com/post/ctr.html</id>
    <published>2019-10-24T13:13:35.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<p>去年看的 <a href="https://book.douban.com/subject/30416291/" target="_blank" rel="noopener">AI极简经济学</a> 中提到一个观点：AI 对企业的贡献是带来强大的推荐预测能力，比如打开手机淘宝，首屏大量的推荐商品。作者猜想未来的某一天，淘宝上的商家可以直接把预测的商品寄到你家，然后由你选择是否购买。支撑这个想法的关键是推荐系统中的点击率预测技术（CTR，Click-Through-Rate），大量的学术机构和商业公司发表相关的论文。目前所做的业务模型中，也参考了很多 CTR 中的方法。自己也看过一些这个领域的论文，并且做了一些笔记。没有太多将笔记单独整理发出来的意义，通过这一篇阅读小结，和大家分享我的学习过程。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;去年看的 &lt;a href=&quot;https://book.douban.com/subject/30416291/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;AI极简经济学&lt;/a&gt; 中提到一个观点：AI 对企业的贡献是带来强大的推荐预测能力，比如打开手机淘
      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="ctr" scheme="https://xiang578.com/tags/ctr/"/>
    
      <category term="fm" scheme="https://xiang578.com/tags/fm/"/>
    
      <category term="gbdt" scheme="https://xiang578.com/tags/gbdt/"/>
    
      <category term="dnn" scheme="https://xiang578.com/tags/dnn/"/>
    
  </entry>
  
  <entry>
    <title>Standford CS231n 2017 课程部分总结</title>
    <link href="https://xiang578.com/post/cs231n-summary.html"/>
    <id>https://xiang578.com/post/cs231n-summary.html</id>
    <published>2019-10-08T13:58:26.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>去年学习这门做的部分笔记，现在分享出来。 笔记格式有些问题，持续整理中。</p></blockquote><ul><li>大量内容参考 <a href="https://github.com/mbadry1/CS231n-2017-Summary/blob/master/README.md" target="_blank" rel="noopener">mbadry1/CS231n-2017-Summary</a></li></ul><h2 id="table-of-contents">Table of contents</h2><ul><li><a href="#standford-cs231n-2017-summary">Standford CS231n 2017 Summary</a><ul><li><a href="#table-of-contents">Table of contents</a></li><li><a href="#course-info">Course Info</a></li><li><a href="#01-introduction-to-cnn-for-visual-recognition">01. Introduction to CNN for visual recognition</a></li><li><a href="#02-image-classification">02. Image classification</a></li><li><a href="#03-loss-function-and-optimization">03. Loss function and optimization</a></li><li><a href="#04-introduction-to-neural-network">04. Introduction to Neural network</a></li><li><a href="#05-convolutional-neural-networks-cnns">05. Convolutional neural networks (CNNs)</a></li><li><a href="#06-training-neural-networks-i">06. Training neural networks I</a></li><li><a href="#07-training-neural-networks-ii">07. Training neural networks II</a></li><li><a href="#08-deep-learning-software">08. Deep learning software</a></li><li><a href="#09-cnn-architectures">09. CNN architectures</a></li></ul></li></ul><h2 id="course-info">Course Info</h2><ul><li>主页: http://cs231n.stanford.edu/</li><li>视频：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">斯坦福深度学习课程CS231N 2017中文字幕版+全部作业参考_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili</a></li><li>大纲：<a href="http://cs231n.stanford.edu/2017/syllabus" target="_blank" rel="noopener">Syllabus | CS 231N</a></li><li>课件：<a href="http://cs231n.stanford.edu/slides/2017/" target="_blank" rel="noopener">Index of /slides/2017</a></li><li>笔记：<a href="https://zhuanlan.zhihu.com/p/21930884" target="_blank" rel="noopener">贺完结！CS231n官方笔记授权翻译总集篇发布</a></li><li>作业仓库：<a href="https://github.com/xiang578/MachineLearning/tree/master/CS231n" target="_blank" rel="noopener">MachineLearning/CS231n at master · xiang578/MachineLearning</a></li><li>总课时: <strong>16</strong></li></ul><h2 id="introduction-to-cnn-for-visual-recognition">01. Introduction to CNN for visual recognition</h2><ul><li>视觉地出现促进了物种竞争。</li><li>ImageNet 是由李飞飞维护的一个大型图像数据集。</li><li>自从 2012 年 CNN 出现之后，图像分类的错误率大幅度下降。 神经网络的深度也从 7 层增加到 2015 年的 152 层。截止到目前，机器分类准确率已经超过人类，所以 ImageNet 也不再举办相关比赛。</li><li>CNN 在 1998 年就被提出，但是这几年才流行开来。主要原因有：1) 硬件发展，并行计算速度提到 2）大规模带标签的数据集。</li><li>Gola: Understand how to write from scratch, debug and train convolutional neural networks.</li></ul><h2 id="image-classification">02. Image classification</h2><ul><li>图像由一大堆没有规律的数字组成，无法直观的进行分类，所以存在语义鸿沟。分类的挑战有：视角变化、大小变化、形变、遮挡、光照条件、背景干扰、类内差异。<ul><li><img src="/file/2019-10-08-15387098703701.jpg"></li></ul></li><li>Data-Driven Approach<ul><li>Collect a dataset of images and labels</li><li>Use Machine Learning to train a classifier</li><li>Evaluate the classifier on new images</li></ul></li><li>图像分类流程：输入、学习、评估</li><li>图像分类数据集：<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">CIFAR-10</a>，这个数据集包含了60000张32X32的小图像。每张图像都有10种分类标签中的一种。这60000张图像被分为包含50000张图像的训练集和包含10000张图像的测试集。</li><li>一种直观的图像分类算法：K-nearest neighbor(knn)<ul><li>为每一张需要预测的图片找到距离最近的 k 张训练集中的图片，然后选着在这 k 张图片中出现次数最多的标签做为预测图片的标签（多数表决）。</li><li>训练过程：记录所有的数据和标签 <span class="math inline">\({O(1)}\)</span></li><li>预测过程：预测给定图片的标签 <span class="math inline">\({O(n)}\)</span></li><li>Hyperparameters：k and the distance Metric</li><li>Distance Metric<ul><li>L1 distance(Manhattan Distance)</li><li>L2 distance(Euclidean Distance)</li></ul></li><li>knn 缺点<ul><li>Very slow at test time</li><li>Distance metrics on pixels are not informative</li></ul></li><li>反例：下面四张图片的 L2 距离相同<ul><li><img src="/file/2019-10-08-15387110626779.jpg" title="fig:" alt="-w622"></li></ul></li></ul></li><li>Hyperparameters: choices about the algorithm that we set ranther than learn</li><li>留一法 Setting Hyperparameters by Cross-validation:<ul><li>将数据划分为 f 个集合以及一个 test 集合，数据划分中药保证数据集的分布一致。</li><li>给定超参数，利用 f-1 个集合对算法进行训练，在剩下的一个集合中测试训练效果，重复这一个过程，直到所有的集合都当过测试集。</li><li>选择在训练集中平均表现最好的超参数。</li></ul></li><li>Linear classification: <code>Y = wX + b</code><ul><li>b 为 bias，调节模型对结果的偏好</li><li>通过最小化损失函数来，来确定 w 和 b 的值。</li></ul></li><li><strong>Linear SVM</strong>: classifier is an option for solving the image classification problem, but the curse of dimensions makes it stop improving at some point. <span class="citation" data-cites="todo">@todo</span></li><li><strong>Logistics Regression</strong>: 无法解决非线性的图像数据</li></ul><h2 id="loss-function-and-optimization">03. Loss function and optimization</h2><ul><li>通过 Loss function 评估参数质量<ul><li>比如 <span class="math display">\[L=\frac{1}{N}\sum_iL_i\left(f\left(x_i,W\right),y_i\right)\]</span></li></ul></li><li>Multiclass SVM loss 多分类支持向量机损失函数<ul><li><span class="math display">\[L_i=\sum_{j \neq y_j}\max\left(0,s_j-s_{y_i}+1\right)\]</span></li><li>这种损失函数被称为合页损失 Hinge loss</li><li>SVM 的损失函数要求正确类别的分类分数要比其他类别的高出一个边界值。</li><li>L2-SVM 中使用平方折叶损失函数<span class="math display">\[\max(0,-)^2\]</span>能更强烈地惩罚过界的边界值。但是选择使用哪一个损失函数需要通过实验结果来判断。</li><li>举例<ul><li><img src="/file/2019-10-08-15388343449162.jpg"></li><li>根据上面的公式计算：<span class="math display">\[L = \max(0,437.9-(-96.8)) + \max(0,61.95-(-96.8))=695.45\]</span></li><li>猫的分类得分在三个类别中不是最高得，所以我们需要继续优化。</li></ul></li></ul></li><li>Suppose that we found a W such that L = 0. Is this W unique?<ul><li>No! 2W is also has L = 0!</li></ul></li><li>Regularization: 正则化，向某一些特定的权值 W 添加惩罚，防止权值过大，减轻模型的复杂度，提高泛化能力，也避免在数据集中过拟合现象。<ul><li><span class="math display">\[L=\frac{1}{N}\sum_iL_i\left(f\left(x_i,W\right),y_i\right) + \lambda R(W)\]</span></li><li><code>R</code> 正则项 <span class="math display">\[\lambda\]</span> 正则化参数</li></ul></li><li>常用正则化方法<ul><li>L2<span class="math display">\[\begin{matrix} R(W)=\sum_{k}\sum_l W^2_{k,l} \end{matrix}\]</span></li><li>L1<span class="math display">\[\begin{matrix} R(W)=\sum_{k}\sum_l \left\vert W_{k,l} \right\vert \end{matrix}\]</span></li><li>Elastic net(L1 + L2): <span class="math display">\[\begin{matrix} R(W)=\sum_{k}\sum_l \beta W^2_{k,l} + \left\vert W_{k,l} \right\vert \end{matrix}\]</span></li><li>Dropout</li><li>Batch normalization</li><li>etc</li></ul></li><li>L2 惩罚倾向于更小更分散的权重向量，L1 倾向于稀疏项。</li><li>Softmax function：<ul><li><span class="math display">\[f_j(z)=\frac{e^{s_i}}{\sum e^{s_j}}\]</span></li><li>该分类器将输出向量 f 中的评分值解释为没有归一化的对数概率，通过归一化之后，所有概率之和为1。</li><li>Loss 也称交叉熵损失 cross-entropy loss <span class="math display">\[L_i = - \log\left(\frac{e^{s_i}}{\sum e^{s_j}}\right)\]</span></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">f = np.array([<span class="number">123</span>, <span class="number">456</span>, <span class="number">789</span>]) <span class="comment"># 例子中有3个分类，每个评分的数值都很大</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># 不妙：数值问题，可能导致数值爆炸</span></span><br><span class="line"><span class="comment"># 那么将f中的值平移到最大值为0：</span></span><br><span class="line">f -= np.max(f) <span class="comment"># f becomes [-666, -333, 0]</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># 现在OK了，将给出正确结果</span></span><br></pre></td></tr></table></figure><ul><li>SVM 和 Softmax 比较<ol type="1"><li>评分，SVM 的损失函数鼓励正确的分类的分值比其他分类的分值高出一个边界值。</li><li>对数概率，Softmax 鼓励正确的分类归一化后的对数概率提高。</li><li>Softmax 永远不会满意，SVM 超过边界值就满意了。</li></ol></li><li>Optimization：最优化过程<ul><li>Follow the slope<ul><li><img src="/file/2019-10-08-15388374738605.jpg"></li></ul></li></ul></li><li>梯度是函数的斜率的一般化表达，它不是一个值，而是一个向量，它是各个维度的斜率组成的向量。<ul><li>Numerical gradient: Approximate, slow, easy to write. (But its useful in debugging.)</li><li>Analytic gradient: Exact, Fast, Error-prone. (Always used in practice)</li><li>实际应用中使用分析梯度法，但可以用数值梯度法去检查分析梯度法的正确性。</li></ul></li><li>利用梯度优化参数的过程：<code>W = W - learning_rate * W_grad</code></li><li>learning_rate 被称为是学习率，是一个比较重要的超参数</li><li>Stochastic Gradient Descent SGD 随机梯度下降法<ul><li>每次使用一小部分的数据进行梯度计算，这样可以加快计算的速度。</li><li>每个批量中只有1个数据样本，则被称为随机梯度下降（在线梯度下降）</li></ul></li><li>图像分类任务中三大关键部分：<ol type="1"><li>评分函数</li><li>损失函数：量化某个具体参数 <span class="math inline">\({W}\)</span> 的质量</li><li>最优化：寻找能使得损失函数值最小化的参数 <span class="math inline">\({W}\)</span> 的过程</li></ol></li></ul><h2 id="introduction-to-neural-network">04. Introduction to Neural network</h2><ul><li>反向传播：在已知损失函数 <span class="math inline">\({L}\)</span> 的基础上，如何计算导数<span class="math inline">\({\nabla _WL}\)</span>？</li><li>计算图<ul><li>由于计算神经网络中某些函数的梯度很困难，所以引入计算图的概念简化运算。</li><li>在计算图中，对应函数所有的变量转换成为计算图的输入，运算符号变成图中的一个节点（门单元）。</li></ul></li><li>反向传播：从尾部开始，根据链式法则递归地向前计算梯度，一直到网络的输入端。<ul><li><img src="/file/2019-10-08-15390088806657.jpg" title="fig:" alt="-w1107"></li><li>绿色是正向传播，红色是反向传播。</li></ul></li><li>对于计算图中的每一个节点，我们需要计算这个节点上的局部梯度，之后根据链式法则反向传递梯度。</li><li>Sigmoid 函数：<span class="math inline">\({f(w,x)=\frac{1}{1+e^{-(w_0x_0+w_1x_1+w_2)}}}\)</span><ul><li><img src="/file/2019-10-08-15390092983570.jpg"></li><li>对于门单元 <span class="math inline">\({\frac{1}{x}}\)</span>，求导的结果是 <span class="math inline">\({-\frac{1}{x^2}}\)</span>，输入为 1.37，梯度返回值为 1.00，所以这一步中的梯度是 <span class="math inline">\({(\frac{-1}{1.37^2})*1.00=-0.53}\)</span>。</li><li>模块化思想：对 <span class="math inline">\({\sigma(x)=\frac{1}{1+e^{-x}}}\)</span> 求导的结果是 <span class="math inline">\({(1-\sigma(x))\sigma(x)}\)</span>。如果 sigmoid 表达式输入值为 1.0 时，则前向传播中的结果是 0.73。根据求导结果计算可得局部梯度是 <span class="math inline">\({(1-0.73)*0.73=0.2}\)</span>。</li></ul></li><li>Modularized implementation: forward/backwar API</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultuplyGate</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  x,y are scalars</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x,y)</span>:</span></span><br><span class="line">    z = x*y</span><br><span class="line">    self.x = x  <span class="comment"># Cache</span></span><br><span class="line">    self.y = y<span class="comment"># Cache</span></span><br><span class="line">    <span class="comment"># We cache x and y because we know that the derivatives contains them.</span></span><br><span class="line">    <span class="keyword">return</span> z</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(dz)</span>:</span></span><br><span class="line">    dx = self.y * dz         <span class="comment">#self.y is dx</span></span><br><span class="line">    dy = self.x * dz</span><br><span class="line">    <span class="keyword">return</span> [dx, dy]</span><br></pre></td></tr></table></figure><ul><li>深度学习框架中会实现的门单元：Multiplication、Max、Plus、Minus、Sigmoid、Convolution</li><li>常用计算单元<ul><li><strong>加法门单元：</strong>把输出的梯度相等地分发给它所有的输入，这一行为与输入值在前向传播时的值无关。</li><li><strong>取最大值门单元：</strong>将梯度转给前向传播中值最大的那个输入，其余输入的值为0。</li><li><strong>乘法门单元：</strong>等值缩放。局部梯度就是输入值，但是需要相互交换，然后根据链式法则乘以输出值得梯度。</li></ul></li><li>Neural NetWorks<ul><li>(Before) Linear score function <span class="math display">\[f = Wx\]</span></li><li>(Now) 2-layer Neural NetWork <span class="math display">\[f=W_2\max(0,W_1x)\]</span></li><li>ReLU <span class="math display">\[\max(0,x)\]</span> 是激活函数，如果不使用激活函数，神经网络只是线性模型的组合，无法拟合非线性情况。</li><li>神经网络是更复杂的模型的基础组件</li></ul></li></ul><h2 id="convolutional-neural-networks-cnns">05. Convolutional neural networks (CNNs)</h2><ul><li>这一轮浪潮的开端：<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">AlxNet</a></li><li>卷积神经网络<ul><li>Fully Connected Layer 全连接层：这一层中所有的神经元链接在一起。</li><li>Convolution Layer：<ul><li>通过参数共享来控制参数的数量。Parameter sharing</li><li>Sparsity of connections</li></ul></li><li>卷积神经网络能学习到不同层次的输入信息</li><li>常见的神经网络结构：<code>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</code></li><li>使用小的卷积核大小的优点：多个卷积层与非线性的激活层交替的结构，比单一卷积层的结构更能提取出深层的更好地特征。而且使用的参数也会更少</li></ul></li><li>计算卷积层输出<ul><li>stride 是卷积核在移动时的步长</li><li>通用公式 (N-F)/stride + 1<ul><li>stride 1 =&gt; (7-3)/1 + 1 = 5</li><li>stride 2 =&gt; (7-3)/2 + 1 = 3</li><li>stride 3 =&gt; (7-3)/3 + 1 = 2.33</li></ul></li><li>Zero pad the border: 用零填充所有的边界，保证输入输出图像大小相同，保留图像边缘信息，提高算法性能<ul><li>步长为 1 时，需要填充的边界计算公式：(F-1)/2<ul><li>F = 3 =&gt; zero pad with 1</li><li>F = 5 =&gt; zero pad with 2</li><li>F = 7 =&gt; zero pad with 3</li></ul></li></ul></li><li>计算例子<ul><li>输入大小 <code>32*32*3</code> 卷积大小 10 5*5 stride 1 pad 2</li><li>output <code>32*32*10</code></li><li>每个 filter 的参数数量：<code>5*5*3+1 =76</code> bias</li><li>全部参数数量 76*10=760</li></ul></li></ul></li><li>卷积常用超参数设置<ul><li>卷积使用小尺寸滤波器</li><li>卷积核数量 K 一般为 2 的次方倍</li><li>卷积核的空间尺寸 F</li><li>步长 S</li><li>零填充数量 P</li></ul></li><li>Pooling layer<ul><li>降维，减少参数数量。在卷积层中不对数据做降采样</li><li>卷积特征往往对应某个局部的特征，通过池化聚合这些局部特征为全局特征</li></ul></li><li>Max pooling<ul><li>2*2 stride 2</li><li>避免区域重叠</li></ul></li><li>Average pooling</li></ul><h2 id="training-neural-networks-i">06. Training neural networks I</h2><ul><li><p>Activation functions 激活函数</p><ul><li>不使用激活函数，最后的输出会是输入的线性组合。利用激活函数对数据进行修正。</li><li><img src="/file/2019-10-08-15395012747510.jpg"></li><li>Sigmoid<ul><li>限制输出在 [0,1]区间内</li><li>firing rate</li><li>二分类输出层激活函数</li><li>Problem<ul><li>梯度消失：x很大或者很小时，梯度很小，接近于0（考虑图像中的斜率。无法得到梯度反馈。</li><li>输出不是 0 均值的数据，梯度更新效率低</li><li>exp is a bit compute expensive</li></ul></li></ul></li><li>tanh<ul><li>输出范围 [-1, 1]</li><li>0 均值</li><li>x 很大时，依然没有梯度</li><li><span class="math inline">\({f(x)=\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}}\)</span></li><li><span class="math inline">\({1-(tanh(x))^2}\)</span></li></ul></li><li>RELU rectified linear unit 线性修正单元<ul><li>一半空间梯度不会饱和，计算速度快，对结果又有精确的计算</li><li>不是 0 均值</li></ul></li><li>Leaky RELU<ul><li><code>leaky_RELU(x) = max(0.01x, x)</code></li><li>梯度不会消失</li><li>需要学习参数</li></ul></li><li>ELU<ul><li>比 ReLU 好用</li><li>反激活机制</li></ul></li><li>Maxout<ul><li>maxout(x) = max(w1.T<em>x + b1, w2.T</em>x + b2)</li><li>梯度不会消失</li><li>增大参数数量</li></ul></li><li>激活函数选取经验<ul><li>使用 ReLU ，但要仔细选取学习率</li><li>尝试使用 Leaky ReLU Maxout ELU</li><li>使用 tanh 时，不要抱有太大的期望</li><li>不要使用 sigmoid</li></ul></li></ul></li><li><p>数据预处理 Data Preprocessing</p><ul><li>均值减法：对数据中每个独立特征减去平均值，从几何上来看是将数据云的中心都迁移到原点。</li><li>归一化：将数据中的所有维度都归一化，使数值范围近似相等。但是在图像处理中，像素的数值范围几乎一致，所以不需要额外处理。</li></ul><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X -= np.mean(X, axis = <span class="number">1</span>)</span><br><span class="line">X /= np.std(X, axis =<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><ul><li>图像归一化<ul><li>Subtract the mean image AlexNet<ul><li>mean image 32,32,3</li></ul></li><li>Subtract per-channel mean VGGNet<ul><li>mean along each channel = 3 numbers</li></ul></li><li>如果需要进行均值减法时，均值应该是从训练集中的图片平均值，然后训练集、验证集、测试集中的图像再减去这个平均值。</li></ul></li><li>Weight Initialization<ul><li>全零初始化<ul><li>网络中的每个神经元都计算出相同的输出，然后它们就会在反向传播中计算出相同的梯度。神经元之间会从源头上对称。</li></ul></li><li>Small random numbers<ul><li>初始化权值要非常接近 0 又不能等于 0。将权重初始化为很小的数值，以此来打破对称性</li><li>randn 函数是基于零均值和标准差的高斯分布的随机函数</li><li>W = 0.01 * np.random.rand(D,H)</li><li>问题：一个神经网络的层中的权重值很小，那么在反向传播的时候就会计算出非常小的梯度。会减小反向传播中的“梯度信号”，在深度网络中就会出现问题。</li></ul></li><li>Xavier initialization<ul><li>W = np.random.rand(in, out) / np.sqrt(in)</li><li>校准方差，解决输入数据量增长，随机初始化的神经元输出数据的分布中的方差也增大问题。</li></ul></li><li>He initialization<ul><li>W = np.random.rand(in, out) / np.sqrt(in/2)</li></ul></li></ul></li><li>Batch normalization<ul><li>保证输入到神经网络中的数据服从标准的高斯分布</li><li>通过批量归一化可以加快训练的速度</li><li>步骤<ul><li>首先计算每个特征的平均值和平方差</li><li>通过减去平局值和除以方差对数据进行归一化</li><li><code>Result = gamma * normalizedX + beta</code><ul><li>对数据进行线性变换，相当于对数据分布进行一次移动，可以恢复数据之前的分布特征</li></ul></li></ul></li><li>BN 的好处<ul><li>加快训练速度</li><li>可以使用更快的而学习率</li><li>减少数据对初始化权值的敏感程度</li><li>相当于进行一次正则化</li></ul></li><li>BN 适用于卷积神经网络和常规的 DNN，在 RNN 和增强学习中表现不是很好</li></ul></li><li>Babysitting the Learning Provess</li><li>Hyperparameter Optimization<ul><li>Cross-validation 策略训练</li><li>小范围内随机搜索</li></ul></li></ul></li></ul><h2 id="training-neural-networks-ii">07. Training neural networks II</h2><ul><li>Optimization Algorithms:<ul><li><p>SGD 的问题</p><ul><li><code>x += - learning_rate * dx</code></li><li>梯度在某一个方向下降速度快，在其他方向下降缓慢</li><li>遇到局部最小值点，鞍点</li></ul></li><li><p>mini-batches GD</p><ul><li>Shuffling and Partitioning are the two steps required to build mini-batches</li><li>Powers of two are often chosen to be the mini-batch size, e.g., 16, 32, 64, 128.</li></ul></li><li><p>SGD + Momentun</p><ul><li>动量更新：从物理学角度启发最优化问题</li><li><code>v = rho * vx + learning_rate * dx; x += v</code></li><li>rho 被看做是动量，其物理意义与摩擦系数想类似，常取 0.9 或0.99</li></ul></li><li><p>Nestrov momentum</p><ul><li><img src="/file/2019-10-08-15499574039274.jpg"></li><li><code>v_prev = v; v = mu * v - learning_rate * dx; x += -mu * v_prev + (1 + mu) * v</code></li></ul></li><li><p>AdaGrad</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">grad_squared = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">  dx = compute_gradient(x)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># here is a problem, the grad_squared isn't decayed (gets so large)</span></span><br><span class="line">  grad_squared += dx * dx</span><br><span class="line">  </span><br><span class="line">  x -= (learning_rate*dx) / (np.sqrt(grad_squared) + <span class="number">1e-7</span>)</span><br></pre></td></tr></table></figure></p></li><li><p>RMSProp</p><ul><li>自适应学习率方法</li><li>cache = decay_rate * cache + (1 - decay_rate) * dx**2</li><li>x += - learning_rate * dx / (np.sqrt(cache) + eps)</li></ul></li><li><p>Adam</p><ul><li>RMSProp + Momentum</li><li>It calculates an exponentially weighted average of past gradients, and stores it in variables <span class="math inline">\(v\)</span> (before bias correction) and <span class="math inline">\(v^{corrected}\)</span> (with bias correction).</li><li>It calculates an exponentially weighted average of the squares of the past gradients, and stores it in variables <span class="math inline">\(s\)</span> (before bias correction) and <span class="math inline">\(s^{corrected}\)</span> (with bias correction).</li><li>It updates parameters in a direction based on combining information from "1" and "2".</li><li>The update rule is, for <span class="math inline">\(l = 1, ..., L\)</span>: <span class="math display">\[\begin{cases}v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial \mathcal{J} }{ \partial W^{[l]} } \\v^{corrected}_{dW^{[l]}} = \frac{v_{dW^{[l]}}}{1 - (\beta_1)^t} \\s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial \mathcal{J} }{\partial W^{[l]} })^2 \\s^{corrected}_{dW^{[l]}} = \frac{s_{dW^{[l]}}}{1 - (\beta_1)^t} \\W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}_{dW^{[l]}}}{\sqrt{s^{corrected}_{dW^{[l]}}} + \varepsilon}\end{cases}\]</span> where:</li><li>t counts the number of steps taken of Adam</li><li>L is the number of layers</li><li><span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are hyperparameters that control the two exponentially weighted averages.</li><li><span class="math inline">\(\alpha\)</span> is the learning rate</li><li><span class="math inline">\(\varepsilon\)</span> is a very small number to avoid dividing by zero</li></ul></li><li><p>Learning decay</p><ul><li>学习率随着训练变化，比如每一轮在前一轮的基础上减少一半。</li><li>防止学习停止</li></ul></li><li><p>Second order optimization</p></li></ul></li><li>Regularization<ul><li>Dropout<ul><li>每一轮中随机使部分神经元失活，减少模型对神经元的依赖，增强模型的鲁棒性。</li></ul></li></ul></li><li>Transfer learning<ul><li>CNN 中的人脸识别，可以在大型的模型基础上利用少量的相关图像进行继续训练。</li></ul></li></ul><h2 id="cnn-architectures">09. CNN architectures</h2><ul><li>研究模型的方法：搞清楚每一层的输入和输出的大小关系。</li><li>LeNet - 5 [1998]<ul><li>60k 参数</li><li>深度加深，图片大小减少，通道数量增加</li><li>ac: Sigmod/tanh</li></ul></li><li>AlexNet [2012]<ul><li>(227,227,3) （原文错误）</li><li>60M 参数</li><li>LRN：局部响应归一化，之后很少使用</li></ul></li><li>VGG - 16 [2015]<ul><li>138 M</li><li>结构不复杂，相对一致，图像缩小比例和通道增加数量有规律</li></ul></li><li>ZFNet [2013]<ul><li>在 AlexNet 的基础上修改<ul><li><code>CONV1</code>: change from (11 x 11 stride 4) to (7 x 7 stride 2)</li><li><code>CONV3,4,5</code>: instead of 384, 384, 256 filters use 512, 1024, 512</li></ul></li></ul></li><li>VGG [2014]<ul><li>模型中只使用 3*3 conv：与 77 卷积有相同的感受野，而且可以将网络做得更深。比如每一层可以获取到原始图像的范围：第一层 33，第二层 55，第三层 77。</li><li>前面的卷积层参数量很少，模型中大部分参数属于底部的全连接层。</li></ul></li></ul><p><img src="/file/2019-10-08-15705415499052.jpg"></p><ul><li>GoogLeNet<ul><li>引入 <code>Inception module</code><ul><li>design a good local network topology (network within a network) and then stack these modules on top of each other</li><li>该模块可以并行计算</li><li>conv 和 pool 层进行 padding，最后将结果 concat 在一起</li></ul></li></ul></li></ul><figure><img src="/file/2019-10-08-15705420412305.jpg" alt="Reset"><figcaption>Reset</figcaption></figure><ul><li>ResNet<ul><li>目标：深层模型表现不应该差于浅层模型，解决随着网络加深，准确率下降的问题。</li><li><code>Y = (W2* RELU(W1x+b1) + b2) + X</code></li><li>如果网络已经达到最优，继续加深网络，residual mapping会被设置为 0，一直保存网络最优的情况。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;去年学习这门做的部分笔记，现在分享出来。 笔记格式有些问题，持续整理中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;大量内容参考 &lt;a href=&quot;https://github.com/mbadry1/CS231n-2017-Summa
      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="ml, course" scheme="https://xiang578.com/tags/ml-course/"/>
    
  </entry>
  
  <entry>
    <title>(WDR) Learning to Estimate the Travel Time</title>
    <link href="https://xiang578.com/post/wdr.html"/>
    <id>https://xiang578.com/post/wdr.html</id>
    <published>2019-07-28T14:14:33.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>严重申明：本篇文章所有信息从论文、网络等公开渠道中获得，不会透露滴滴地图 ETA 相关实现。</p></blockquote><p>这篇论文是滴滴时空数据 2018 年在 KDD 上发表的关于在 ETA 领域应用深度学习的文章，里面提到的深度学习方法大家都耳熟能详，主要是属于工业界的创新。说点题外话，<a href="https://www.zhihu.com/question/22385673/answer/522580778" target="_blank" rel="noopener">你为什么从滴滴出行离职？ - 知乎</a> 中提到一点：</p><blockquote><p>8.同年大跃进，在滴滴中高层的眼里，没有BAT。滴滴单量超淘宝指日可待，GAFA才是滴滴要赶超的对象。百度系，LinkedIn系，学院派，uber帮，联想系，MBB就算了，据说连藤校都混成了一个小圈子。。一个项目A team ，B team。一个ETA，投入了多少人力自相残杀？MAPE做到0%又如何？用户体验就爆表了吗？长期留存就高枕无忧了吗？风流总被雨打风吹去，滴滴是二龙山，三虫聚首？是不是正确的事情不知道，反正跟着公司大势所趋，升D10保平安。</p></blockquote><p>简单介绍一下背景：ETA 是 Estimate Travel Time 的缩写，中文大概能翻译成到达时间估计。这个问题描述是：在某一个时刻，估计从 A 点到 B 点需要的时间。对于滴滴，关注的是司机开车把乘客从起点送到终点需要的时间。抽象出来 ETA 就是一个时间空间信息相关的回归问题。CTR 中常用的方法都可以在这里面尝试。</p><p>对于这个问题：文章中提到一个最通用的方法 Route ETA：即在获得 A 点到 B 点路线的情况下，计算路线中每一段路的行驶时间，并且预估路口的等待时间。最终 ETA 由全部时间相加得到。这种方法实现起来很简单，也能拿到一些收益。但是仔细思考一下，没有考虑未来道路的同行状态变化情况以及路线的拓扑关系。针对这些问题，文章中提到滴滴内部也有利用 GBDT 或者 FM 的方法解决 ETA 问题，不过没有仔细写实现的方法，我也不好继续分析下去。</p><h3 id="评价指标">评价指标</h3><p>对于 ETA 问题来说，工业界和学术界常用的指标是 MAPE(mean absolute percentage error)，<span class="math inline">\({y_i}\)</span> 是司机实际从 A 点到 B 点花费的时间，<span class="math inline">\({f(x_i)}\)</span> 是 ETA 模型估计出来的时间。得到计算公式如下：</p><p><span class="math display">\[{min_f \sum_{i=1}^{N}\frac{|y_i - f(x_i)|}{y_i}}\]</span></p><p>多说一句，如果使用 GBDT 模型实现 ETA 时，这个损失函数的推导有点困难，全网也没有看见几个人推导过。</p><p>这个公式主要考虑预估时间偏差大小对用户感知体验的影响，目前我们更加关心极端 badcase 对用户的影响。</p><h3 id="特征">特征</h3><ul><li>特征：<ul><li>空间特征：路线序列、道路等级、POI等</li><li>时间特征：月份、星期、时间片等</li><li>路况特征：道路的通行速度、拥堵程度</li><li>个性化信息：司机特征、乘客特征、车辆特征</li><li>附近特征：天气、交通管制</li></ul></li></ul><h3 id="模型">模型</h3><p>WDR 模型，包含 3 个部分： - Wide Learning Models：利用交叉积学习信息，泛化能力。 - Deep Neural networks：对 sparse feature 做一次 Embedding，使用 3 层 MLP 和 ReLU 的网络。 - Long-Short Term Memory：解决 Wide &amp; Deep 没用使用路线的顺序特征，利用 LSTM 学习 link 信息以及序列信息，最后一个单元的隐藏状态作为输出。 - Regressor： 将 3 个模型的输出综合起来，作为最后的 ETA 预估。MAPE 作为损失函数，利用 BP 训练模型。</p><figure><img src="/file/15643233780326.jpg" alt="-w962"><figcaption>-w962</figcaption></figure><p>上面模型中使用的特征分类： - Dense feature：行程级别的实数特征，比如起终点球面距离、起终点 GPS 坐标等。 - Sparse feature：行程级别的离散特征，比如时间片编号、星期几、天气类型等。 - Sequential feature：link 级别的特征，实数特征直接输入模型，而离散特征先做 embedding 再输入模型。注意，这里不再是每个行程一个特征向量，而是行程中每条 link 都有一个特征向量。比如，link 的长度、车道数、功能等级、实时通行速度等。</p><h3 id="评估">评估</h3><p>包括两部分：离线评估和在线评估。</p><p>离线评估中取滴滴 2017 年北京前6个月的订单数据，分成两类 pickup （平台给司机分单后，司机开车去接乘客的过程）和 trip （司机接到乘客并前往目的地的过程）。具体数据集划分如下。</p><p><img src="/file/15643234056004.jpg"></p><p>离线使用 MAPE 来评价模型。在线评估时，为了更好的与用户体验挂钩，采用多个指标来衡量 ETA 的效果。包括： - APE20: absolute percentage error 小于 20% 的订单占比。（越大越好） - Badcase率：APE 大于 50% 或者 AE 大于 180s 的订单占比，定义为对用户造成巨大影响的情况。（越小越好） - 低估率：低估订单的比例。（越小越好）</p><p>离线结果如下图所示，说来汗颜 PTTE 和 TEMP 是什么算法我都不知道…… WD-MLP 指的是将 WDR 中的 R 部分换成 MLP 。最终 WDR 较 route-ETA 有巨大提升，而且 LSTM 引入的序列信息也在 pikcup 上提升了 0.75%。文章的最后还提出来，LSTM 也可以换成是 Attention，这样替换有什么优点和缺点留给大家思考。</p><p><img src="/file/15643234140115.jpg"></p><p>在线实验结果如下图所示，滴滴 ETA MAPE 明显小于 com1、com2、com3 ，这三家地图公司具体是哪三家，大家也能猜到吧。</p><p><img src="/file/15643234258049.jpg"></p><h3 id="eta-服务工程架构">ETA 服务工程架构：</h3><figure><img src="/file/15643234352132.jpg" alt="-w486"><figcaption>-w486</figcaption></figure><p>从上面的图中可以看出 ETA 服务工程架构主要包括三个部分： - Data Aggregation：包括利用 Map Matching 将司机上传到平台的 GPS 对应到滴滴的 Map Info 中得到司机真实行驶过的路线信息，Order Context 指的是订单相关的信息，augmented Data 额外数据比如上文说的交通情况相关信息。 - Offline Training：利用上一步得到的历史数据训练模型。这里可以值得一提的是，ETA 模型是和时间强相关的（节假日和工作日的数据分布明显不同），所以在文章中作者指出将拿出最新的一部分数据用来 fine-tune 训练出来的 WDR 模型。 - Online Service：这里需要一个完整的模型服务系统，其他公司也有很多分享，所以原文没有多提。</p><h2 id="总结">总结</h2><p>从上面简单的介绍来看，ETA 可以使用 CTR 和 NLP 领域的很多技术，大有可为。最后，滴滴 ETA 团队持续招人中（社招、校招、日常实习等），感兴趣者快快和我联系。</p><h2 id="参考">参考</h2><blockquote><ul><li><a href="https://www.leiphone.com/news/201808/EmRne91YDwwNCl4A.html" target="_blank" rel="noopener">KDD 2018：滴滴提出WDR模型显著提升ETA预测精度 | 雷锋网</a></li><li><a href="http://www.semocean.com/lbs%e5%b7%a5%e4%b8%9a%e7%95%8ceta%e5%ba%94%e7%94%a8%e5%8f%8a%e6%bb%b4%e6%bb%b4wdr%e6%8a%80%e6%9c%af/" target="_blank" rel="noopener">LBS工业界ETA应用及滴滴WDR技术 – Semocean</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;严重申明：本篇文章所有信息从论文、网络等公开渠道中获得，不会透露滴滴地图 ETA 相关实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这篇论文是滴滴时空数据 2018 年在 KDD 上发表的关于在 ETA 领域应用深度学习的文章，里面提到的深度学
      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="lstm" scheme="https://xiang578.com/tags/lstm/"/>
    
      <category term="widedeep" scheme="https://xiang578.com/tags/widedeep/"/>
    
      <category term="didi" scheme="https://xiang578.com/tags/didi/"/>
    
  </entry>
  
  <entry>
    <title>(FM) Factorization Machines</title>
    <link href="https://xiang578.com/post/fm.html"/>
    <id>https://xiang578.com/post/fm.html</id>
    <published>2019-07-28T10:18:52.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<p>Factorization Machines(FM) 由日本 Osaka University 的 Steffen Rendle [1] 在 2010 年提出,是一种常用的因子机模型。</p><h2 id="fm">FM</h2><p>假设现在有一个电影评分的任务，给定如下如所示的特征向量 x（包括用户名、当前在看的电影、已经打分的电影、时间特征、之前看的电影），预测用户对当前观看电影的评分。</p><figure><img src="/file/15643023365227.jpg" alt="电影评分"><figcaption>电影评分</figcaption></figure><p>作者在线性回归模型的基础上，添加交叉项部分，用来自动组合二阶特征。 <span class="math display">\[\hat y(x):= w_0 + \sum_{i=1}^{n} w_ix_i + \sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_iy_i\]</span></p><p>其中交叉特征的权重由两个向量的点积得到，可以解决没有在模型中出现的特征组合权重问题，以及减少参数数量。</p><p><span class="math display">\[W_{i,j}=\left \langle v_i,v_j \right \rangle = \sum_{f=1}^kv_{i,f} \cdot v_{j,f}\]</span></p><p>通过下面的方法来化简交叉项权重计算，算法复杂度降到线性。</p><p><span class="math display">\[\sum_{i=1}^n \sum_{j=i+1}^n \left \langle v_i,v_j \right \rangle x_iy_i = \frac{1}{2}\sum^k_{f=1} \left( \left(\sum_{i=1}^nv_{i,f}x_i \right)^2 - \sum^n_{i=1} v^2_{i,f} x_i^2 \right)\]</span></p><p>对交叉项部分的求导：</p><p><span class="math display">\[\frac{\partial}{\partial \theta} \hat y \left( x \right) =\begin{cases}1, &amp; \text{ if $\theta$ is $w_0$} \\x_i, &amp; \text{ if $\theta$ is ${w_i}$} \\x_i\sum^n_{j=1} v_{j,f}x_j - v_{i,f}x_i^2, &amp;\text{if $\theta$ is ${v_{i,f}}$}  \end{cases}\]</span></p><p>其中 <span class="math inline">\({\sum^n_{j=1} v_{j,f}x_j}\)</span> 与 <span class="math inline">\({x_i}\)</span> 无关，可以在计算导数前预处理出来。</p><h3 id="fm-vs-svm">FM vs SVM</h3><p>对于经典的特征组合问题，不难想到使用 SVM 求解。Steffen 在论文中也多次将 FM 和 SVM 做对比。</p><p>在考虑 SVM 的 Polynomial kernel 为 <span class="math inline">\({K(\mathbf{x}, \mathbf{z}) :=(\langle\mathbf{x}, \mathbf{z}\rangle+ 1)^{2}}\)</span>，映射 <span class="math display">\[\begin{array}{l}{\phi(\mathbf{x}) :=\left(1, \sqrt{2} x_{1}, \ldots, \sqrt{2} x_{n}, x_{1}^{2}, \ldots, x_{n}^{2}\right.} {\sqrt{2} x_{1} x_{2}, \ldots, \sqrt{2} x_{1} x_{n}, \sqrt{2} x_{2} x_{3}, \ldots, \sqrt{2} x_{n-1} x_{n} )}\end{array}\]</span></p><p>SVM 的公式可以转化为：</p><p><span class="math display">\[\begin{aligned} \hat{y}(\mathbf{x})=w_{0}+\sqrt{2} \sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n} w_{i, i}^{(2)} x_{i}^{2} &amp;+\sqrt{2} \sum_{i=1}^{n} \sum_{j=i+1}^{n} w_{i, j}^{(2)} x_{i} x_{j} \end{aligned}\]</span></p><p>论文中提到一句上面的公式中 <span class="math inline">\({w_{i}}\)</span> 和 <span class="math inline">\({w_{i,i}}\)</span> 表达能力类似，我猜这也是为什么 FM 中没有自身交叉项的原因吧。</p><p>FM 相比于 SVM 有下面三个特点： 1. SVM 中虽然也有特征交叉项，但是只能在样本中含有相对应的特征交叉数据时才能学习。但是 FM 能在数据稀疏的时候学习到交叉项的参数。 2. SVM 问题无法直接求解，常用的方法是根据拉格朗日对偶性将原始问题转化为对偶问题。 3. 在使用模型预测时，SVM 依赖部分训练数据（支持向量），FM 模型则没有这种依赖。</p><h3 id="rank">Rank</h3><p>FM 用来做回归和分类都很好理解，简单写一下如何应用到排序任务中。以 pairwise 为例。假设排序结果有两个文档 <span class="math inline">\({x_i}\)</span> 和 <span class="math inline">\({x_j}\)</span>，显然用户点击文档有先后顺序，如果先点击 <span class="math inline">\({x_i}\)</span>，记 label <span class="math inline">\({y_{ij}=1}\)</span>，反之点击 <span class="math inline">\({x_j}\)</span>，label <span class="math inline">\({y_{ij}=0}\)</span>。模型需要去预测 <span class="math inline">\({\hat y_{ij} = sigmoid(\hat y_i - \hat y_j)}\)</span>。</p><p>参考逻辑回归，用最大似然对参数进行估计，得到损失函数为 <span class="math inline">\({L=\log(1+\exp(-(\hat y(x_i)-\hat y(x_j))}\)</span>。优化过程和前面提到类似。</p><h2 id="nfm">NFM</h2><p>NFM 和 AFM 两篇论文是同一个作者写的，所以文章的结构很相近。</p><p>FM 模型由于复杂度问题，一般只使用特征二阶交叉的形式，缺少对 higher-order 以及 non-liner 特征的交叉能力。NFM 尝试通过引入 NN 来解决这个问题。</p><p>NFM 的结构如下：第一项和第二项是线性回归，第三项是神经网络。神经网络中利用 FM 模型的二阶特征交叉结果做为输入，学习数据之间的高阶特征。与直接使用高阶 FM 模型相比，可以降低模型的训练复杂度，加快训练速度。</p><p><span class="math display">\[\hat{y}_{N F M}(\mathbf{x})=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+f(\mathbf{x})\]</span></p><p>NFM 的神经网络部分包含 4 层，分别是 Embedding Layer、Bi-Interaction Layer、Hidden Layers、Prediction Score。</p><figure><img src="/file/15643037118475.jpg" alt="NFM"><figcaption>NFM</figcaption></figure><ul><li>Embedding Layer 层对输入的稀疏数据进行 Embedding 操作。最常见的 Embedding 操作是在一张权值表中进行 lookup ，论文中作者强调他们这一步会将 Input Feture Vector 中的值与 Embedding 向量相乘。</li><li>Bi-Interaction Layer 层是这篇论文的创新，对 embedding 之后的特征两两之间做 element-wise product，并将结果相加得到一个 k 维（Embeding 大小）向量。这一步相当于对特征的二阶交叉，与 FM 类似，这个公式也能进行化简：</li></ul><p><span class="math display">\[f_{B I}\left(\mathcal{V}_{x}\right)=\sum_{i=1}^{n} \sum_{j=i+1}^{n} x_{i} \mathbf{v}_{i} \odot x_{j} \mathbf{v}_{j} =\frac{1}{2}\left[\left(\sum_{i=1}^{n} x_{i} \mathbf{v}_{i}\right)^{2}-\sum_{i=1}^{n}\left(x_{i} \mathbf{v}_{i}\right)^{2}\right]\]</span></p><ul><li>Hidden Layers 层利用常规的 DNN 学习高阶特征交叉</li><li>Prdiction Layer 层输出最终的结果： <span class="math display">\[\begin{aligned} \hat{y}_{N F M}(\mathbf{x}) &amp;=w_{0}+\sum_{i=1}^{n} w_{i} x_{i} +\mathbf{h}^{T} \sigma_{L}\left(\mathbf{W}_{L}\left(\ldots \sigma_{1}\left(\mathbf{W}_{1} f_{B I}\left(\mathcal{V}_{x}\right)+\mathbf{b}_{1}\right) \ldots\right)+\mathbf{b}_{L}\right) \end{aligned}\]</span></li></ul><p>实验结果：</p><p><img src="/file/15643059963915.jpg"></p><h2 id="afm">AFM</h2><p>AFM(Attentional Factorization Machine), 在 FM 的基础上将 Attention 机制引入到交叉项部分，用来区分不同特征组合的权重。</p><p><span class="math display">\[\hat{y}_{A F M}(\mathbf{x})=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\mathbf{p}^{T} \sum_{i=1}^{n} \sum_{j=i+1}^{n} a_{i j}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}\]</span></p><p>单独看上面公式中的第三项结构：</p><p><img src="/file/15643076111641.jpg"></p><ul><li>Embedding Layer 与 NFM 里面的作用一样，转化特征。</li><li>Pair-wise Interaction Layer 是将特征两两交叉，如果对这一步的结果求和就是 FM 中的交叉项。</li><li>Attention 机制在 Attention-based Pooling 层引入。将 Pair-wise Interaction Layer 中的结果输入到 Attention Net 中，得到特征组合的 score <span class="math inline">\({a_{i j}^{\prime} }\)</span>，然后利用 softmax 得到权重矩阵 <span class="math inline">\({a_{ij}}\)</span>。 <span class="math display">\[\begin{aligned} a_{i j}^{\prime} &amp;=\mathbf{h}^{T} \operatorname{Re} L U\left(\mathbf{W}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+\mathbf{b}\right) \\ a_{i j} &amp;=\frac{\exp \left(a_{i j}^{\prime}\right)}{\sum_{(i, j) \in \mathcal{R}_{x}} \exp \left(a_{i j}^{\prime}\right)} \end{aligned}\]</span></li><li>最后将 Pair-wise Interaction Layer 中的二阶交叉结果和权重矩阵对应相乘求和得到 AFM 的交叉项。</li></ul><p><img src="/file/15643086043204.jpg"></p><p>和前一节的实验结果对比，AFM 效果比 NFM 要差一些。这大概就能说明为什么论文中提到 NFM，但是最后没有把 NFM 的结果贴出来，实在是机智。又回到，发论文是需要方法有创新，还是一味追求 state-of-the-art。</p><h2 id="参考资料">参考资料</h2><blockquote><ul><li><a href="http://kubicode.me/2018/02/23/Deep%20Learning/Deep-in-out-Factorization-Machines-Series/#NFM" target="_blank" rel="noopener">深入浅出Factorization Machines系列 | Kubi Code'Blog</a></li><li><a href="https://zhuanlan.zhihu.com/p/34666996" target="_blank" rel="noopener">FM模型在LTR类问题中的应用 - 知乎</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Factorization Machines(FM) 由日本 Osaka University 的 Steffen Rendle [1] 在 2010 年提出,是一种常用的因子机模型。&lt;/p&gt;
&lt;h2 id=&quot;fm&quot;&gt;FM&lt;/h2&gt;
&lt;p&gt;假设现在有一个电影评分的任务，给定
      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="fm" scheme="https://xiang578.com/tags/fm/"/>
    
  </entry>
  
  <entry>
    <title>(Wide&amp;Deep) Wide &amp; Deep Learning for Recommender Systems</title>
    <link href="https://xiang578.com/post/wide-and-deep.html"/>
    <id>https://xiang578.com/post/wide-and-deep.html</id>
    <published>2019-07-02T12:56:43.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>这是一篇推荐系统相关的论文，场景是谷歌 Play Store 的 App 推荐。文章开头，作者点明推荐系统需要解决的两个能力： memorization 和 generalization。</p><p><strong>memorization</strong> 指的是学习数据中出现过的组合特征能力。最常使用的算法是 Logistic Regression，简单、粗暴、可解释性强，而且会人工对特征进行交叉，从而提升效果。但是，对于在训练数据中没有出现过的特征就无能为力。</p><p><strong>generalization</strong> 指的是通过泛化出现过特征从解释新出现特征的能力。常用的是将高维稀疏的特征转换为低维稠密 embedding 向量，然后使用 fm 或 dnn 等算法。与 LR 相比，减少特征工程的投入，而且对没有出现过的组合有较强的解释能力。但是当遇到的用户有非常小众独特的爱好时（对应输入的数据非常稀疏和高秩），模型会过度推荐。</p><p>综合前文 ，作者提出一种新的模型 Wide &amp; Deep。</p><h2 id="模型">模型</h2><p>从文章题目中顾名思义，Wide &amp; Deep 是融合 Wide Models 和 Deep Models 得到，下图形象地展示出来。</p><figure><img src="/file/15610337156969.jpg" alt="Wide &amp; Deep Models"><figcaption>Wide &amp; Deep Models</figcaption></figure><p><strong>Wide Component</strong> 是由一个常见的广义线性模型：<span class="math inline">\({y=w^Tx+b}\)</span>。其中输入的特征向量 <span class="math inline">\({x}\)</span> 包括两种类型：原始输入特征（raw input features）和组合特征（transformed features）。</p><p>常用的组合特征公式如下： <span class="math display">\[{\phi_k(x)=\prod_{i=1}^dx_i^{c_{ki}},c_{ki}\in\{0,1\}}\]</span> <span class="math inline">\({c_{ki}}\)</span> 代表对于第k个组合特征是否包含第i个特征。<span class="math inline">\({x_i}\)</span>是布尔变量，代表第i个特征是否出现。例如对于组合特征 <code>AND(gender=female, language=en)</code> 当且仅当 x 满足<code>(“gender=female” and “language=en”)</code>时，<span class="math inline">\({\phi_k(x)=1}\)</span>。</p><p><strong>Deep Component</strong> 是一个标准的前馈神经网络，每一个层的形式诸如：<span class="math inline">\({a^{(l+1)}=f(W^{(l)}a^{(l)} + b^{(l)})}\)</span>。对于输入中的 categorical feature 需要先转化成低维稠密的 embedding 向量，再和其他特征一起喂到神经网络中。</p><p>对于这种由基础模型组合得到的新模型，常用的训练形式有两种：joint training 和 ensemble。ensemble 指的是，不同的模型单独训练，且不共享信息（比如梯度）。只有在预测时根据不同模型的结果，得到最终的结果。相反，joint training 将不同的模型结果放在同一个损失函数中进行优化。因此，ensmble 要且模型独立预测时就有有些的表现，一般而言模型会比较大。由于 joint training 训练方式的限制，每个模型需要由不同的侧重。对于 Wide&amp;Deep 模型来说，wide 部分只需要处理 Deep 在低阶组合特征学习的不足，所以可以使用简单的结果，最终完美使用 joint traing。</p><p>预测时，会将 Wide 和 Deep 的输出加权得到结果。在训练时，使用 logistic loss function 做为损失函数。模型优化时，利用 mini-batch stochastic optimization 将梯度信息传到 Wide 和 Deep 部分。然后，Wide 部分通过 FTRL + L1 优化，Deep 部分通过 AdaGrad 优化。</p><h2 id="实验">实验</h2><p>本篇论文选择的实验场景是谷歌 app 商店的应用推荐，根据用户相关的历史信息，推荐最有可能会下载的 App。</p><p>使用的模型如下： <img src="/file/15611212418726.jpg" alt="Wide &amp; Deep model structure for apps recommendation."></p><p>一些细节： - 对于出现超过一定次数的 categorical feature，ID 化后放入到模型中。 - Continuous real-valued features 通过 cumulative distribution function 归一化到 [0, 1] 区间。 - categorical feature 由 32 维 embedding 向量组成，最终的输入到 Deep 部分的向量大概在 1200 维。 - 每天在前一天 embedding 和模型的基础上进行增量更新。</p><p>实验结果：</p><figure><img src="/file/15610335523493.jpg" alt="实验结果"><figcaption>实验结果</figcaption></figure><p>Wide &amp; Deep 模型相对于其他两个模型毫无疑问有提升。但结果中也一个反常的现象：单独使用 Deep 模型离线 AUC 指标比单独使用 Wide 模型差，但是线上对比实验时却有较大的提升。论文中作者用了一句：线下实验中的特征是固定的，线上实验会遇到很多没有出现过的特征组合，Deep 相对于 Wide 有更好的模型泛化能力，所以会有反常现象。由于笔者工作中不关注 AUC，也没有办法继续分析。</p><h2 id="总结">总结</h2><p>作者从推荐系统的的 memorization 和 generalization 入手，设计出新的算法框架。通过线上和线下实验实验，证明 Deep 和 Wide 联合是必须的且有效的。最终也在自己的业务场景带来提升。</p><h2 id="reference">Reference</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/37733208" target="_blank" rel="noopener">Wide &amp; Deep Learning for Recommender Systems - 知乎</a></li><li><a href="https://zhuanlan.zhihu.com/p/53361519" target="_blank" rel="noopener">详解 Wide &amp; Deep 结构背后的动机 - 知乎</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;这是一篇推荐系统相关的论文，场景是谷歌 Play Store 的 App 推荐。文章开头，作者点明推荐系统需要解决的两个能力： memorization 和 generalization。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;memoriz
      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="ctr" scheme="https://xiang578.com/tags/ctr/"/>
    
      <category term="dnn" scheme="https://xiang578.com/tags/dnn/"/>
    
      <category term="lr" scheme="https://xiang578.com/tags/lr/"/>
    
  </entry>
  
  <entry>
    <title>Best of iPhone 2019 软件清单</title>
    <link href="https://xiang578.com/post/best-of-iphone-2019.html"/>
    <id>https://xiang578.com/post/best-of-iphone-2019.html</id>
    <published>2019-06-22T13:32:22.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<p>一直想做一个推荐软件的系列文章，不过完成 2017 年的<a href="https://xiang578.com/post/iphone5s.html">iPhone软件清单</a> 后就没有动力……很多时候在思考，自己为什么一定要使用 iPhone？iOS 中的软件正是最好的答案，让每一个人享受科技带来的快乐。</p><p>这一篇文章和 2017 年的形式一样，删除常用的软件，推荐一些我认为有趣的软件。自从 iOS 12 中引入屏幕时间，今年的推荐顺序就按照屏幕时间中的排序。</p><p>目前使用设备：iPhone XR &amp; Apple Watch Series 4</p><ul><li>Inoreader：RSS 订阅服务商以及 RSS 阅读器。随着这两年对推荐算法相关的新闻阅读器批判，RSS 大有一股复新之势。可惜的是在去年年底左右，inoreader 中每个免费帐号只能关注 150 个订阅源。目前，我通过使用多个帐号来临时解决。</li><li>脉脉：职场社交软件。有匿名区以及公司圈，定期查看公司内部的吐槽和爆料。用 Leader 的话来说，整天操 M6 的心。</li><li>Keep/Nike Running/健身记录：锻炼相关 App 集合。Keep 和 Apple Watch 的配合太差，很多数据不能同步。自带的健身记录展示数据不够详细。Nike Running 不太用。</li><li>Overcast：免费且功能强大的播客软件，良心到只有少量的播客相关广告。喜欢智能播放和人声增强功能。最近，也支持章节播放功能。</li><li>AutoSleep：配合 Apple Watch 实现睡眠监控功能。原来大致为读取 Apple Watch 写入健康中的数据判断是否入睡以及睡眠质量。由于硬件的限制，很多时候还是不太准确。不过我也和网上说的一样，每天起来需要看这软件中的评分，判断昨天睡的如何……</li><li>Kindle：管它微信阅读如何火爆，不忘初心依旧选择 Kindle。配合 Kindle Unlimted，可以阅读很多好书。</li><li>Google 相册：免费强大的照片管理软件，允许谷歌优化照片质量的后，可以无限存储。</li><li>Quantumult：梯子软件，美区下载，比小火箭好用。</li><li>OmniFoucs：GTD 软件，居然使用的正版……</li><li>Anki：多年之后，我的摘抄终于有了存放之地。</li><li>Day One：日记软件，喜欢里面的去年今天功能，陆续把日记导入中。</li><li>Pocket：稍后读。</li><li>1 Password：密码软件，全平台通用。</li><li>熊猫吃短信：垃圾短信过滤，可以自己配置规则把公司的报警短信给屏蔽了。</li><li>Ulysses：Markdown 软件，iOS 版也包含在 SetApp 订阅。</li></ul><p>在与 2017 版相比，有两个趋势：1. 减少很多与学习强相关的软件。 2. 越来越多的付费或者订阅制软件。期待明年。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一直想做一个推荐软件的系列文章，不过完成 2017 年的&lt;a href=&quot;https://xiang578.com/post/iphone5s.html&quot;&gt;iPhone软件清单&lt;/a&gt; 后就没有动力……很多时候在思考，自己为什么一定要使用 iPhone？iOS 中的软件正是
      
    
    </summary>
    
      <category term="生活志" scheme="https://xiang578.com/categories/%E7%94%9F%E6%B4%BB%E5%BF%97/"/>
    
    
      <category term="iOS" scheme="https://xiang578.com/tags/iOS/"/>
    
      <category term="app" scheme="https://xiang578.com/tags/app/"/>
    
      <category term="best of" scheme="https://xiang578.com/tags/best-of/"/>
    
  </entry>
  
  <entry>
    <title>Practical Lessons from Predicting Clicks on Ads at Facebook(gbdt + lr)</title>
    <link href="https://xiang578.com/post/gbdt_lr.html"/>
    <id>https://xiang578.com/post/gbdt_lr.html</id>
    <published>2019-06-16T12:56:43.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<p><strong>主题：</strong>Facebook 2014 年发表的广告点击预测文章。最主要是提出经典 GBDT+LR 模型，可以自动实现特征工程，效果好比于人肉搜索。另外，文章中还给出一个 online learning 的工程框架。</p><p><strong>问题：</strong> - GBDT 如何处理大量 id 类特征 - 广告类对于 user id 的处理：利用出现的频率以及转化率来代替 - id 特征放在 lr 中处理。 - GBDT+LR 和 RF+LR 的区别 - 选出能明显区分正负样本的特征的变换方式，转换成 one hot 有意义 - RF + LR 可以并行训练，但是 RF 中得到的区分度不高</p><p><strong>收获：</strong></p><ul><li>数据支撑去做决策，收获和实验数量成正比。</li><li>CTR click through rate，点击率</li><li>评价指标：<ul><li>Normalized Entropy：越小模型越好</li><li>Calibration：预测点击数除以真实点击数</li><li>AUC 正样本出现在负样本前面的概率。</li></ul></li><li>数据新鲜度：模型天级训练比周级训练在 NE 下降 1%。</li><li>GBDT 和 LR 模型采用不同的更新频率，解决训练耗时不同。但是 GBDT 重新训练之后，LR 必须要重新训练。</li></ul><h2 id="网络">网络：</h2><h3 id="gbdt-lr">GBDT + LR</h3><p>利用 GBDT 模型进行自动特征组合和筛选，然后根据样本落在哪棵树哪个叶子生成一个 feature vector 输入到 LR 模型中。这种方法的有点在于两个模型在训练过程从是独立，不需要进行联合训练。</p><p>GBDT 由多棵 CART 树组成，每一个节点按贪心分裂。最终生成的树包含多层，相当于一个特征组合的过程。根据规则，样本一定会落在一个叶子节点上，将这个叶子节点记为1，其他节点设为0，得到一个向量。比如下图中有两棵树，第一棵树有三个叶子节点，第二棵树有两个叶子节点。如果一个样本落在第一棵树的第二个叶子，将它编码成 [0, 1, 0]。在第二棵树落到第一个叶子，编码成 [1, 0]。所以，输入到 LR 模型中的向量就是 [0, 1, 0, 1, 0]</p><p><img src="/file/15529885839484.jpg"></p><h3 id="online-learning">Online Learning</h3><p>文章中提到的 Online Learning 包括三个部分： - Joiner 将每次广告展示结果（特征）是否用户点击（标签） join 在一起形成一个完成的训练数据； - Trainer 定时根据一个 small batch 的数据训练一个模型； - Ranker 利用上一个模块得到模型预测用户点击。</p><p><img src="/file/15529904431696.jpg"></p><p>注意的点： - waiting window time：给用户展示广告之后，我们只能知道用户点击的广告，也就是模型中的正样本。负样本需要设置一个等待时间来判断，即超过某一个时间没有观测到用户点击某一个广告，就认为这是一个负样本。另外设置这个时间也是一个技术活，时间过短导致click没有及时join到样本上，时间太长数据实时性差以及有存储的压力。最后，无论如何都会有一些数据缺失，为了避免累积误差，需要定期重新训练整个模型。 - request ID：人家的模型是分布式架构的，需要使用 request ID 来匹配每次展示给用户的结果以及click。为了实现快速匹配，使用 HashQueue 来保存结果。 - 监控：避免发生意向不到的结果，导致业务损失。我们的实时模型也在上线前空跑了好久。</p><h2 id="实验">实验：</h2><h4 id="有无-gbdt-特征对比">有无 GBDT 特征对比</h4><p>训练两个 LR 模型，一个模型输入样本经过 GBDT 得到的特征，另外一个不输入。混合模型比单独 LR 或 Tree <img src="/file/15529901354294.jpg"></p><h4 id="学习率选择">学习率选择</h4><p>5 种学习率，前三个每一个特征设置一个学习率，最后两种全局学习率。 <img src="/file/15541928146842.jpg"></p><p>结果：应该给每一个特征设置一个不同的学习率，而且学习率应该随着轮次缓慢衰减。 <img src="/file/15541931302704.jpg"></p><h4 id="gbdt-参数相关实验">GBDT 参数相关实验</h4><ul><li>前面的树会带来大量的收益，但是树越多训练越慢。</li><li>特征重要程度，累加不同树上某个特征的得分减少贡献。</li><li>两种特征：<ul><li>上下文，冷启动的时候比较重要，与数据新鲜度有关。</li><li>历史史特征，权重比较大，关键在于长时间积累。</li></ul></li></ul><h4 id="采样">采样</h4><p>训练数据大多，需要进行采样。</p><ul><li><p>uniform subsampling ：无差别采样。使用 10 % 的样本，NE 减少 1 % <img src="/file/15542640937514.jpg"></p></li><li><p>negative down subsampling ：对负样本进行下采样。但不是负采样率越低越好，比如下面的图中0.0250就可能是解决了正负样本不平衡问题。最后的CTR指标结果需要重新进行一次映射。 <img src="/file/15542641884458.jpg"></p></li></ul><h3 id="reference">Reference</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/57987311" target="_blank" rel="noopener">回顾Facebook经典CTR预估模型 - 知乎</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;主题：&lt;/strong&gt;Facebook 2014 年发表的广告点击预测文章。最主要是提出经典 GBDT+LR 模型，可以自动实现特征工程，效果好比于人肉搜索。另外，文章中还给出一个 online learning 的工程框架。&lt;/p&gt;
&lt;p&gt;&lt;strong
      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="gbdt" scheme="https://xiang578.com/tags/gbdt/"/>
    
      <category term="machine learing" scheme="https://xiang578.com/tags/machine-learing/"/>
    
      <category term="lr" scheme="https://xiang578.com/tags/lr/"/>
    
  </entry>
  
  <entry>
    <title>「Rime 鼠须管」小鹤双拼配置指南</title>
    <link href="https://xiang578.com/post/rime.html"/>
    <id>https://xiang578.com/post/rime.html</id>
    <published>2019-06-15T13:21:14.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/file/15599183665365.jpg"></p><h2 id="引言">引言</h2><p>如何将汉字输入到计算机中是一个编码有关的问题，目前市面上主流的方案包括音码、形码、音形码。和大多数人一样，之前我一直使用全拼，而且得益于 NLP 技术发展，使用搜狗输入法搭配云词库，输入效率可以媲美五笔输入法。</p><p>但是今天要和大家分享，是从年初开始使用的全新音码输入方案——小鹤双拼。最初关于双拼的概念来自李笑来《把时间当作朋友》：</p><blockquote><p>在很长的一段时间里，我常言之凿凿地对同学们说“练习打字完全是浪费时间。”我当时的逻辑是这样的。首先，我认为王码五笔字型输入法是给打字员用的。为什么要学它？难道你将来想要当个打字员？我总觉得五笔字型知识一种抄写输入法，因为用他输入时只能边看边打。而对真正创造内容的人来说，先用纸和笔写出来再录入电脑，还有比这更荒诞的事情吗？学习拆字学法已经很累人了，还要练什么指法，见鬼。更不用说这种所谓的输入法对思考的干扰——不仅要把字拆开再输入，还要按照莫名其妙的方法拆字。其次，盲打。我现在不是盲打，只是两根手指输入速度就已经很快了（至少比手写快）。</p><p>这样看来，我还有必要学习什么五笔字型和盲打吗？</p><p>在我有了这些定见很久之后，发生了一件事情。</p><p>那是在1997年，我25岁。当时互联网除了聊天室和论坛，几乎没有什么实际的应用。适逢windows捆绑了哈尔滨工业大学开发的“微软拼音输入法1.0”，某天下午，当我在网上和一位永远都不会知道是谁的女生放肆地聊了两个小时之后，突然发现自己竟已无师自通地学会了所谓的“盲打”了！在这之后的一段时间里，我身边甚至很多人羡慕我打字的速度。为了让自己的打字速度再快一点，我索性花了差不多20分钟，把原本默认的“全拼输入”改成了“”双拼输入“。而这还远远不够。后来，我增设了”慢放模糊音“（不区分z/zh、c/ch、s⇧），又把打字速度提高了一些。这时我第一次意识到‘有些认识，哪怕是简单的常识，也需要亲身经历后才能真正体会”。只有拥有无与伦比的打字速度，才会体会打字速度快的好处。</p><p>打字速度提升后，我发现自己不再讨厌在读书的时候做笔记了，因为在键盘上敲字相对于笔写字来说轻松太多。我开始大段地纪录感悟，有时甚至干脆整篇摘抄原文！</p></blockquote><p>李笑来思考的问题正是如何利用最小的代价快速的输入文字。这里代价包括两个方面，输入方案的学习成本以及输入文字的速度。简单分析一下，主流输入法需要用户在键盘上敲击一些字符，然后映射到汉字。就是说输入文字的速度和两个因数有关：敲击键盘的次数（对应计算机中的码长）以及重码的字符数量（对于拼音输入法来说，这里指的是每个拼音对应多少的字）。</p><p>从这两个指标来说，五笔应该是接近输入法的极限，五次敲击键盘肯定能选定你需要的汉字。但是学习五笔需要记忆大量的说是有序其实没有太多规律的字根，学习曲线不是一般的陡峭。几年前，自己尝试跟着网上的视频教程学习，最后还是太复杂而放弃。</p><p>这时候要介绍一下双拼输入法，它是一种基于全拼的激进改良版拼音输入法。简单来说，它将一个汉字的拼音分成声母和韵母两个部分，输入一个拼音只需要按两个键（减少键盘的敲击次数但是没有减少重码率）。比如对于“拼音”两个字来说，全拼需要输入 <code>pinyin</code> 六个字符，换成是双拼，只需要输入 4 个字符 <code>pbyb</code>。具体介绍可以看 <a href="https://sspai.com/post/32809" target="_blank" rel="noopener">做少数派中的少数派：双拼输入快速入门</a>。</p><p>由于双拼有声母和韵母，需要先从键盘上进行一次映射，所以有很多的输入方案。我自己入门使用的是小鹤双拼，也推荐大家使用这个方案。主要原因有两点：声母和韵母全部放在字母键上（微软双拼中要用到 <code>;</code> 键，以及 iOS12 和 MacOS 中自带的输入法都支持这个方案（国内那几个流氓输入法更不用提）。</p><p>下图是一张小鹤双拼的输入法键位图，其中黑色的字符代表是键盘上的什么键，棕色的代表这个键表示声母时是什么，蓝色的代表这个键表示韵母时是什么。学习双拼的过程也很简单，拼音本身就会，无非是熟悉键位。从我自己的角度来说，每天抽出几分看一下键位图，再在 <a href="https://api.ihint.me/shuang/" target="_blank" rel="noopener">双拼练习 @ BlueSky</a> （相关的介绍可以看：<a href="https://sspai.com/post/40185" target="_blank" rel="noopener">快速上手双拼，可以尝试这个练习平台 - 少数派</a>）网站上练习 5 分钟，一周后可以完全脱离键位图来打字，之后就是孰能生巧的过程。</p><p><img src="/file/15600908556759.jpg"></p><p>说回来当你学习了这么强大的内功之后，自然需要神兵来辅助你输入。在饱受国内的流氓输入法侵害之后（比如输入到一半给你跳一个什么斗图功能提示），我遇到今天的主角 <a href="https://rime.im/" target="_blank" rel="noopener">RIME | 中州韻輸入法引擎</a>，它是由佛振开发的一种开源输入框架，业内人士称之为「神级输入法」。上一个有类似拉风的称号的软件还是「神级编辑器」—— Vim。Rime 有趣的一点是在不同的平台上有不同的名字，包括 Linux 上的「中州韵」，Win 上的「小狼毫」以及 Mac 上的「鼠须管」。稍微有文化的人可以反应过来，后面两个正是两种不同的毛笔名字。</p><p>简单总结一下为什么要使用鼠须管：一是安全，不会出现什么输入法读取你个人信息更甚者是密码发送到服务器，也不知道他们用来机器学习什么；二是配置全平台同步，解决多台设备的输入法配置问题；三是快，不会出现输入法跟不上我的打字速度而导致思路中断的情况。</p><h2 id="安装">安装</h2><p>在 <a href="https://rime.im/download/" target="_blank" rel="noopener">下載及安裝 | RIME | 中州韻輸入法引擎</a> 主页，你可以找到对应不同平台的安装方法。</p><p>对于 MacOS 来说，可以在终端中使用 <code>curl -fsSL https://git.io/rime-install | bash -s -- :preset double-pinyin</code> 安装软件本体。<code>preset double-pinyin</code> 指定下载的时候默认包括双拼输入方案。</p><h2 id="配置">配置</h2><p>防止配置时候出现各种意想不到的情况，首先推荐阅读官方文档 <a href="https://github.com/rime/home/wiki/CustomizationGuide" target="_blank" rel="noopener">CustomizationGuide · rime/home Wiki</a>。</p><p>Rime 的配置文件默认放在 <code>~/Library/Rime</code>，而且是一种扩展 yaml 文件。默认的文件名为 <code>.schema.yaml</code>，比如小鹤双拼相关的默认配置在 <code>double_pinyin_flpy.schema.yaml</code> 中。如果我们自己想添加一些设置，推荐写在以<code>.custom.yaml</code> 结尾的新文件中，比如 <code>double_pinyin_flypy.custom.yaml</code></p><h3 id="default.custom.yaml">default.custom.yaml</h3><p>这个文件写一些全局的配置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">patch:</span></span><br><span class="line">  <span class="attr">switcher:</span></span><br><span class="line">    <span class="attr">caption:</span> <span class="string">〔方案选单〕</span></span><br><span class="line">    <span class="attr">hotkeys:</span> <span class="string">Control+grave</span></span><br><span class="line">  <span class="comment"># 候选词数量</span></span><br><span class="line">  <span class="attr">menu:</span></span><br><span class="line">    <span class="attr">page_size:</span> <span class="number">9</span></span><br><span class="line">  <span class="comment"># 使用的输入方案</span></span><br><span class="line">  <span class="attr">schema_list:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">schema:</span> <span class="string">luna_pinyin_simp</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">schema:</span> <span class="string">luna_pinyin</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">schema:</span> <span class="string">double_pinyin_flypy</span></span><br><span class="line">  <span class="comment"># 输入法中英文状态快捷键</span></span><br><span class="line">  <span class="attr">ascii_composer/switch_key:</span></span><br><span class="line">    <span class="attr">Caps_Lock:</span> <span class="string">commit_code</span></span><br><span class="line">    <span class="attr">Control_L:</span> <span class="string">noop</span></span><br><span class="line">    <span class="attr">Control_R:</span> <span class="string">noop</span></span><br><span class="line">    <span class="comment"># 按下左 shift 英文字符直接上屏，不需要再次回车，输入法保持英文状态</span></span><br><span class="line">    <span class="attr">Shift_L:</span> <span class="string">noop</span></span><br><span class="line">    <span class="attr">Shift_R:</span> <span class="string">noop</span></span><br><span class="line">  <span class="comment"># 在一些软件中默认使用英文输入状态</span></span><br><span class="line">  <span class="attr">app_options:</span></span><br><span class="line">    <span class="attr">com.apple.finder:</span> <span class="meta">&amp;a</span></span><br><span class="line">      <span class="attr">ascii_mode:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">no_inline:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">com.googlecode.iterm2:</span> <span class="meta">*a</span></span><br><span class="line">    <span class="attr">com.alfredapp.Alfred:</span> <span class="meta">*a</span></span><br><span class="line">    <span class="attr">com.runningwithcrayons.Alfred-2:</span> <span class="meta">*a</span></span><br><span class="line">    <span class="attr">org.vim.MacVim:</span> <span class="meta">*a</span></span><br><span class="line">    <span class="attr">com.apple.Terminal:</span> <span class="meta">*a</span></span><br></pre></td></tr></table></figure><p>最后在修改配置时，可以查阅 <a href="https://github.com/LEOYoon-Tsaw/Rime_collections/blob/master/Rime_description.md" target="_blank" rel="noopener">Rime_collections/Rime_description.md at master · LEOYoon-Tsaw/Rime_collections</a> 寻找相关信息。</p><h3 id="installation.yaml">installation.yaml</h3><p>配置文件多平台同步相关文件，<code>sync_dir</code> 指定同步文件夹的位置，配合例如坚果云之类的软件实现备份同步。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">distribution_code_name:</span> <span class="string">Squirrel</span></span><br><span class="line"><span class="attr">distribution_name:</span> <span class="string">"鼠鬚管"</span></span><br><span class="line"><span class="attr">distribution_version:</span> <span class="number">0.11</span><span class="number">.0</span></span><br><span class="line"><span class="attr">install_time:</span> <span class="string">"Sun Dec 23 23:42:01 2018"</span></span><br><span class="line"><span class="attr">installation_id:</span> <span class="string">"mac_didi"</span></span><br><span class="line"><span class="attr">sync_dir:</span> <span class="string">"/Users/didi/Documents/rime_sync"</span></span><br><span class="line"><span class="attr">rime_version:</span> <span class="number">1.4</span><span class="number">.0</span></span><br><span class="line"><span class="attr">update_time:</span> <span class="string">"Mon Jun  3 07:18:30 2019"</span></span><br></pre></td></tr></table></figure><h3 id="double_pinyin_flypy.custom.yaml">double_pinyin_flypy.custom.yaml</h3><p>小鹤双拼相关的自用配置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">patch:</span></span><br><span class="line">  <span class="comment"># 引用 `symbols.custom` 文件里面的符号</span></span><br><span class="line">  <span class="comment"># 'punctuator/import_preset': symbols.custom</span></span><br><span class="line">  <span class="attr">'recognizer/patterns/punct':</span> <span class="string">"^/([a-z]+|[0-9])$"</span></span><br><span class="line">  <span class="comment"># 載入朙月拼音擴充詞庫</span></span><br><span class="line">  <span class="attr">"translator/dictionary":</span> <span class="string">ryen</span></span><br><span class="line">  <span class="comment"># 更改‘西文’为‘英文’，‘增广’为‘扩展集’</span></span><br><span class="line">  <span class="attr">punctuator:</span></span><br><span class="line">    <span class="attr">import_preset:</span> <span class="string">symbols.custom</span></span><br><span class="line">    <span class="attr">half_shape:</span></span><br><span class="line">      <span class="string">"#"</span><span class="string">:</span> <span class="string">"#"</span></span><br><span class="line">      <span class="string">"`"</span><span class="string">:</span> <span class="string">"`"</span></span><br><span class="line">      <span class="string">"~"</span><span class="string">:</span> <span class="string">"~"</span></span><br><span class="line">      <span class="string">"@"</span><span class="string">:</span> <span class="string">"@"</span></span><br><span class="line">      <span class="string">"="</span><span class="string">:</span> <span class="string">"="</span></span><br><span class="line">      <span class="string">"/"</span><span class="string">:</span> <span class="string">["/",</span> <span class="string">"÷"</span><span class="string">]</span></span><br><span class="line">      <span class="string">'\': ["、", '</span><span class="string">\']</span></span><br><span class="line">      <span class="string">"'"</span><span class="string">:</span> <span class="string">&#123;pair:</span> <span class="string">["「",</span> <span class="string">"」"</span><span class="string">]&#125;</span></span><br><span class="line">      <span class="string">"["</span><span class="string">:</span> <span class="string">["【",</span> <span class="string">"["</span><span class="string">]</span></span><br><span class="line">      <span class="string">"]"</span><span class="string">:</span> <span class="string">["】",</span> <span class="string">"]"</span><span class="string">]</span></span><br><span class="line">      <span class="string">"$"</span><span class="string">:</span> <span class="string">["¥",</span> <span class="string">"$"</span><span class="string">,</span> <span class="string">"€"</span><span class="string">,</span> <span class="string">"£"</span><span class="string">,</span> <span class="string">"¢"</span><span class="string">,</span> <span class="string">"¤"</span><span class="string">]</span></span><br><span class="line">      <span class="string">"&lt;"</span><span class="string">:</span> <span class="string">["《",</span> <span class="string">"〈"</span><span class="string">,</span> <span class="string">"«"</span><span class="string">,</span> <span class="string">"&lt;"</span><span class="string">]</span></span><br><span class="line">      <span class="string">"&gt;"</span><span class="string">:</span> <span class="string">["》",</span> <span class="string">"〉"</span><span class="string">,</span> <span class="string">"»"</span><span class="string">,</span> <span class="string">"&gt;"</span><span class="string">]</span></span><br><span class="line">  <span class="attr">switches:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ascii_mode</span></span><br><span class="line">      <span class="attr">reset:</span> <span class="number">0</span></span><br><span class="line">      <span class="attr">states:</span> <span class="string">["中文",</span> <span class="string">"英文"</span><span class="string">]</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">full_shape</span></span><br><span class="line">      <span class="attr">states:</span> <span class="string">["半角",</span> <span class="string">"全角"</span><span class="string">]</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">zh_simp</span></span><br><span class="line">      <span class="attr">reset:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">states:</span> <span class="string">["漢字","汉字"]</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ascii_punct</span></span><br><span class="line">      <span class="attr">states:</span> <span class="string">["，。",</span> <span class="string">"，．"</span><span class="string">]</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">extended_charset</span> <span class="comment">#生僻字开关</span></span><br><span class="line">      <span class="attr">states:</span> <span class="string">["通用",</span> <span class="string">"扩展集"</span><span class="string">]</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">show_emoji</span> <span class="comment"># 该项为表情输入，具体内容可见下文中 [关于表情输入] 部分</span></span><br><span class="line">      <span class="attr">reset:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">states:</span> <span class="string">[</span> <span class="string">"🈚️️\uFE0E"</span><span class="string">,</span> <span class="string">"🈶️️\uFE0F"</span> <span class="string">]</span></span><br><span class="line">  <span class="comment"># 输入双拼码的时候不转化为全拼码</span></span><br><span class="line">  <span class="attr">translator/preedit_format:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">  <span class="attr">simplifier:</span></span><br><span class="line">    <span class="attr">option_name:</span> <span class="string">zh_simp</span></span><br><span class="line">  <span class="comment"># 分号上屏二候选词；引号上屏三候选词</span></span><br><span class="line">  <span class="attr">"key_binder/bindings":</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">when:</span> <span class="string">has_menu,</span> <span class="attr">accept:</span> <span class="string">semicolon,</span> <span class="attr">send:</span> <span class="number">2</span> <span class="string">&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">when:</span> <span class="string">has_menu,</span> <span class="attr">accept:</span> <span class="string">apostrophe,</span> <span class="attr">send:</span> <span class="number">3</span> <span class="string">&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">when:</span> <span class="string">paging,</span> <span class="attr">accept:</span> <span class="string">bracketleft,</span> <span class="attr">send:</span> <span class="string">Page_Up</span> <span class="string">&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">when:</span> <span class="string">has_menu,</span> <span class="attr">accept:</span> <span class="string">bracketright,</span> <span class="attr">send:</span> <span class="string">Page_Down</span> <span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="squirrel.custom.yaml">squirrel.custom.yaml</h3><p>自定义皮肤相关文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">patch:</span></span><br><span class="line">  <span class="attr">style:</span></span><br><span class="line">    <span class="attr">color_scheme:</span> <span class="string">psionics</span></span><br><span class="line">    <span class="attr">horizontal:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">inline_preedit:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">candidate_format:</span> <span class="string">"%c\u2005%@ \u2005"</span>   <span class="comment"># 用 1/6 em 空格 U+2005 来控制编号 %c 和候选词 %@ 前后的空间。</span></span><br><span class="line">    <span class="attr">font_point:</span> <span class="number">16</span>                          <span class="comment"># 候选文字大小</span></span><br><span class="line">    <span class="attr">label_font_point:</span> <span class="number">14</span>                    <span class="comment"># 候选编号大小</span></span><br><span class="line">    <span class="attr">corner_radius:</span> <span class="number">5</span>                        <span class="comment"># 候选条圆角</span></span><br><span class="line">    <span class="attr">border_height:</span> <span class="number">0</span>                        <span class="comment"># 窗口边界高度，大于圆角半径才生效</span></span><br><span class="line">    <span class="attr">border_width:</span> <span class="number">0</span>                         <span class="comment"># 窗口边界宽度，大于圆角半径才生效</span></span><br></pre></td></tr></table></figure><p>最后，我的配置在 <a href="https://github.com/xiang578/rime" target="_blank" rel="noopener">xiang578/rime</a> 同步。</p><h2 id="debug">DEBUG</h2><p>Debug 是折腾 rime 不得不面对的一步，主要通过查看 rime 部署的時候 log 文件实现。对于鼠鬚管， log 文件保存在 <code>$TMPDIR/rime.squirrel.*</code> 中。首先在命令行中输入 <code>echo $TMPDIR</code> 获得路径，然后将地址输入到 「访达-前往-前往文件夹...」跳转。点击 <code>rime.squirrel.WARNING</code> 选择显示原身，利用文本编辑器打开。</p><p>文件格式类似于下面：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Log file created at:</span> <span class="number">2019</span><span class="string">/06/07</span> <span class="number">23</span><span class="string">:31:54</span></span><br><span class="line"><span class="attr">Running on machine:</span> <span class="string">didideMiBook-Pro.local</span></span><br><span class="line"><span class="attr">Log line format:</span> <span class="string">[IWEF]mmdd</span> <span class="string">hh:mm:ss.uuuuuu</span> <span class="string">threadid</span> <span class="string">file:line]</span> <span class="string">msg</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:31:54.549346</span> <span class="number">162086912</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">punctuation.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:31:54.554167</span> <span class="number">162086912</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">key_bindings.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:31:54.560144</span> <span class="number">162086912</span> <span class="string">deployment_tasks.cc:179]</span> <span class="string">schema</span> <span class="string">list</span> <span class="string">not</span> <span class="string">defined.</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.133517</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">punctuation.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.135843</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">key_bindings.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.149406</span> <span class="number">161013760</span> <span class="string">config_data.cc:62]</span> <span class="string">nonexistent</span> <span class="string">config</span> <span class="string">file</span> <span class="string">'/Users/didi/Library/Rime/luna_pinyin_simp.custom.yaml'</span><span class="string">.</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.154920</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">punctuation.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.156643</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">key_bindings.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.331344</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">key_bindings.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.333066</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">punctuation.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.668072</span> <span class="number">161013760</span> <span class="string">config_data.cc:62]</span> <span class="string">nonexistent</span> <span class="string">config</span> <span class="string">file</span> <span class="string">'/Users/didi/Library/Rime/stroke.custom.yaml'</span><span class="string">.</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.670761</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">key_bindings.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:13.672724</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">punctuation.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:14.281919</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">punctuation.custom:/patch</span></span><br><span class="line"><span class="string">W0607</span> <span class="number">23</span><span class="string">:36:14.283246</span> <span class="number">161013760</span> <span class="string">config_compiler.cc:391]</span> <span class="attr">inaccessible node:</span> <span class="string">key_bindings.custom:/patch</span></span><br></pre></td></tr></table></figure><h2 id="按右-shift-切换输入法">按右 shift 切换输入法</h2><p>之前使用搜狗输入法时，特别喜欢的一个功能：按右 shift 切换输入法的输入状态，实现暂时切换到英文状态。Rime 作者在 <a href="https://gist.github.com/lotem/2981316" target="_blank" rel="noopener">使用 Control 鍵切換中西文，上屏已輸入的編碼；令 Caps Lock 改變字母的大小寫</a> 中提到一种方案。例如下面：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">patch:</span></span><br><span class="line">  <span class="attr">ascii_composer/good_old_caps_lock:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">ascii_composer/switch_key:</span></span><br><span class="line">    <span class="attr">Caps_Lock:</span> <span class="string">commit_code</span></span><br><span class="line">    <span class="attr">Shift_L:</span> <span class="string">noop</span></span><br><span class="line">    <span class="attr">Shift_R:</span> <span class="string">commit_code</span></span><br><span class="line">    <span class="attr">Control_L:</span> <span class="string">commit_code</span></span><br><span class="line">    <span class="attr">Control_R:</span> <span class="string">commit_code</span></span><br></pre></td></tr></table></figure><p>然而这样修改完成之后，不论按哪个 Shift 键，都会切换到英文输入状态。看前面那个网页下面作者与其他人的讨论中发现，鼠须管无法区分 Shift 键。</p><p>网上查了一下，简单实现的方法是通过 karabiner 软件来改键。详细步骤可以参考 <a href="https://github.com/rime/squirrel/wiki/%E7%A6%81%E7%94%A8-Squirrel-%E8%8B%B1%E6%96%87%E6%A8%A1%E5%BC%8F%EF%BC%8C%E4%BD%BF%E7%94%A8%E5%B7%A6%E4%BE%A7-Shift-%E5%88%87%E6%8D%A2%E4%B8%AD%E8%8B%B1" target="_blank" rel="noopener">禁用 Squirrel 英文模式，使用左侧 Shift 切换中英 · rime/squirrel Wiki</a>。</p><h2 id="reference">Reference</h2><ul><li><a href="https://github.com/xiang578/xiang578.github.io/issues/37" target="_blank" rel="noopener">双拼 · Issue #37 · xiang578/xiang578.github.io</a></li><li><a href="http://zhizhi.betahouse.us/2018/10/17/rime-setup/" target="_blank" rel="noopener">基于Rime的鼠须管输入法配置记录</a></li><li><a href="https://withdewhua.space/2019/01/30/rime-configuration" target="_blank" rel="noopener">Rime 输入法配置记录</a></li><li><a href="https://mritd.me/2019/03/23/oh-my-rime/" target="_blank" rel="noopener">Mac 下调校 Rime - 漠然的博客 | mritd Blog</a></li><li><a href="https://jdhao.github.io/2019/02/18/rime_configuration_intro/" target="_blank" rel="noopener">最新版 Rime 输入法使用 - jdhao's blog</a></li><li><a href="https://scomper.me/gtd/-shu-xu-guan-de-diao-jiao-bi-ji" target="_blank" rel="noopener">「鼠须管」的调教笔记</a></li><li><a href="https://scomper.me/gtd/-shu-xu-guan-de-an-zhuang-he-bu-shu" target="_blank" rel="noopener">「鼠须管」输入方案的添加</a></li><li><a href="https://whyhow.tk/2016/04/29/rime0429.html" target="_blank" rel="noopener">RIME输入法在Finder中自动切换成英文 @ Why &amp; How</a></li><li><a href="https://placeless.net/blog/rime-squirrel-customization-2019#article" target="_blank" rel="noopener">鼠须管配置 2019</a></li><li><a href="https://github.com/rime/squirrel/wiki/%E7%A6%81%E7%94%A8-Squirrel-%E8%8B%B1%E6%96%87%E6%A8%A1%E5%BC%8F%EF%BC%8C%E4%BD%BF%E7%94%A8%E5%B7%A6%E4%BE%A7-Shift-%E5%88%87%E6%8D%A2%E4%B8%AD%E8%8B%B1" target="_blank" rel="noopener">禁用 Squirrel 英文模式，使用左侧 Shift 切换中英 · rime/squirrel Wiki</a></li><li><a href="https://github.com/rime-aca/dictionaries" target="_blank" rel="noopener">rime-aca/dictionaries: Rime詞庫</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/file/15599183665365.jpg&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;
&lt;p&gt;如何将汉字输入到计算机中是一个编码有关的问题，目前市面上主流的方案包括音码、形码、音形码。和大多数人一样，之前我一直使用全拼，而且得益于 NLP 
      
    
    </summary>
    
    
      <category term="rime" scheme="https://xiang578.com/tags/rime/"/>
    
  </entry>
  
  <entry>
    <title>博客维护日志 beta 0.1</title>
    <link href="https://xiang578.com/post/blog-log.html"/>
    <id>https://xiang578.com/post/blog-log.html</id>
    <published>2019-06-15T05:39:49.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>记录博客修修补补的故事</p></blockquote><h2 id="beta-0.1">beta 0.1</h2><ul><li>开始使用版本号来记录博客更新。从 beta 0.1 开始，预计完成博客发布会的计划后（参见：<a href="https://github.com/xiang578/xiang578.github.io/issues/23" target="_blank" rel="noopener">博客发布会 · Issue #23</a>，切换到正式版本。</li><li>本次更新带来最大的变化是在博客中加入豆瓣个人<a href="https://xiang578.com/books">阅读</a>和<a href="https://xiang578.com/movies">观影</a>记录。感谢 <a href="https://github.com/mythsman/hexo-douban" target="_blank" rel="noopener">hexo-douban: A simple plugin for hexo that helps us generate pages for douban books ,movies and games.</a> 提供技术支持。</li></ul><h2 id="beta-0">beta 0</h2><p>早期对博客进行的相关修改有：</p><ul><li><a href="https://xiang578.com/post/how-to-build-a-hexo-blog.html">从零开始利用 hexo + Github/Coding 搭建个人博客 | 算法花园</a></li><li><a href="https://xiang578.com/post/add-return-button-to-blog.html">为博客添加返回顶部按钮 | 算法花园</a></li><li><a href="https://xiang578.com/post/use-travis-ci-to-auto-update.html">博客折腾记：使用 Travis CI 自动部署 | 算法花园</a></li><li><a href="https://xiang578.com/post/use-travis-ci-to-auto-build-blog.html">博客折腾记：使用 Travis CI 自动部署博客 | 算法花园</a></li><li><a href="https://xiang578.com/post/fix-qiniu-test-url-error.html">博客折腾记：修复七牛云测试域名失效问题 | 算法花园</a></li><li><a href="https://xiang578.com/post/use-cos-to-store-blog.html">博客折腾记：主题更新、迁移博客到腾讯云COS以及解决百度收录 | 算法花园</a></li><li><a href="https://xiang578.com/post/meet-leancloud-counter-security-problem.html">博客折腾记：hexo-leancloud-counter-security 与标题中的引号冲突 | 算法花园</a></li></ul><h2 id="博客专栏">博客专栏</h2><ul><li>【每周分享】：每周六更新，记录过去一周，我看到值得分享的内容</li><li>【月读】：每月更新，推荐本月我阅读的一本书</li><li>【数字生活】：我的数字生活实践</li><li>【博客公告】：分享与这个博客维护相关的内容</li></ul><h2 id="博客记录">博客记录</h2><ul><li>本博客采用<a href="https://hexo.io/" target="_blank" rel="noopener">hexo</a>搭建，使用<a href="https://github.com/ahonn/hexo-theme-even" target="_blank" rel="noopener">Even</a>主题</li><li>托管：Coding Pages</li><li>域名：腾讯云</li><li>评论：Disqus</li><li>统计：百度统计</li><li>图床：七牛</li><li>20151006：恢复订阅功能</li><li>20160303：开启分类和请我喝一杯咖啡</li><li>20160623：重新开启评论和百度统计，与自己和解</li><li>20160624：更换主题大道至简Maupassant，增加favicon和apple-touch-icon</li><li>20170104：放弃github+hexo,投入vps+wordpress怀抱,依旧使用maupassant主题</li><li>20170722：主机系统升级失败,从备份中恢复博客,并采用 Twenty Twelve 主题</li><li>20171005：重新投入hexo怀抱，并托管于Coding Pages</li><li>20180101：开启功德箱</li><li>20180501：PV: 657 | UV: 242</li><li>20180528：使用 Travis CI 自动部署</li></ul><h2 id="除虫记录">除虫记录</h2><h3 id="error-cannot-find-module-node-sass-magic-importer">Error: Cannot find module 'node-sass-magic-importer'</h3><p><a href="https://blog.csdn.net/Nalaluky/article/details/82598300" target="_blank" rel="noopener">ERROR in Cannot find module 'node-sass'（已解决） - line - CSDN博客</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install node-sass@latest</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;记录博客修修补补的故事&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;beta-0.1&quot;&gt;beta 0.1&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;开始使用版本号来记录博客更新。从 beta 0.1 开始，预计完成博客发布会的计划后（参见：&lt;a href
      
    
    </summary>
    
    
      <category term="blog" scheme="https://xiang578.com/tags/blog/"/>
    
      <category term="hexo" scheme="https://xiang578.com/tags/hexo/"/>
    
      <category term="vps" scheme="https://xiang578.com/tags/vps/"/>
    
  </entry>
  
  <entry>
    <title>博客折腾记：hexo-leancloud-counter-security 与标题中的引号冲突</title>
    <link href="https://xiang578.com/post/meet-leancloud-counter-security-problem.html"/>
    <id>https://xiang578.com/post/meet-leancloud-counter-security-problem.html</id>
    <published>2019-05-25T13:21:14.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<p>昨天按照 <a href="https://github.com/theme-next/hexo-theme-next/blob/master/docs/LEANCLOUD-COUNTER-SECURITY.md" target="_blank" rel="noopener">hexo-theme-next/LEANCLOUD-COUNTER-SECURITY.md at master · theme-next/hexo-theme-next</a> 这个文档配置博客阅读次数时，遇到 <code>hexo-leancloud-counter-security</code> 插件的一个冲突。</p><p>完成配置使用 <code>hexo -d</code> 时，终端中出现下面的错误提示：</p><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> ATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br><span class="line">SyntaxError: Unexpected token h in JSON at position 30</span><br><span class="line">    at JSON.parse (&lt;anonymous&gt;)</span><br><span class="line">    at /Users/didi/Documents/personal/xiang578.github.io/node_modules/hexo-leancloud-counter-security/index.js:92:42</span><br><span class="line">    at arrayEach (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_lodash@4.17.11@lodash/lodash.js:516:11)</span><br><span class="line">    at Function.forEach (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_lodash@4.17.11@lodash/lodash.js:9344:14)</span><br><span class="line">    at Hexo._callee$ (/Users/didi/Documents/personal/xiang578.github.io/node_modules/hexo-leancloud-counter-security/index.js:83:27)</span><br><span class="line">    at tryCatch (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_regenerator-runtime@0.11.1@regenerator-runtime/runtime.js:62:40)</span><br><span class="line">    at Generator.invoke [as _invoke] (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_regenerator-runtime@0.11.1@regenerator-runtime/runtime.js:296:22)</span><br><span class="line">    at Generator.prototype.(anonymous function) [as next] (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_regenerator-runtime@0.11.1@regenerator-runtime/runtime.js:114:21)</span><br><span class="line">    at step (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_babel-runtime@6.26.0@babel-runtime/helpers/asyncToGenerator.js:17:30)</span><br><span class="line">    at /Users/didi/Documents/personal/xiang578.github.io/node_modules/_babel-runtime@6.26.0@babel-runtime/helpers/asyncToGenerator.js:28:13</span><br><span class="line">    at process._tickCallback (internal/process/next_tick.js:68:7)</span><br></pre></td></tr></table></figure></p><p>看提示貌似是利用 Json 解析字符串的时候出现问题。打开 <code>node_modules/hexo-leancloud-counter-security/index.js:92</code>，对应出现一个解析 JSON的：</p><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="built_in">JSON</span>.parse(memoData[memoIdx].substring(<span class="number">0</span>, memoData[memoIdx].length - <span class="number">1</span>));</span><br></pre></td></tr></table></figure></p><p>js 没有怎么接触过，不知道能不能单步调试之类的，只好祭出输出调试大法，加上两个输出：</p><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">console</span>.log(memoIdx)</span><br><span class="line"><span class="built_in">console</span>.log(memoData[memoIdx])</span><br><span class="line">y = <span class="built_in">JSON</span>.parse(memoData[memoIdx].substring(<span class="number">0</span>,memoData[memoIdx].length - <span class="number">1</span>));</span><br></pre></td></tr></table></figure></p><p>然后再执行 <code>hexo -d</code> 命令，命令行输出为： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">28</span><br><span class="line">&#123;"title":"System.out.println("hello world!");","url":"/post/hello-world.html"&#125;,</span><br><span class="line">FATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br><span class="line">SyntaxError: Unexpected token h in JSON at position 30</span><br><span class="line">    at JSON.parse (&lt;anonymous&gt;)</span><br><span class="line">    at /Users/didi/Documents/personal/xiang578.github.io/node_modules/hexo-leancloud-counter-security/index.js:92:42</span><br><span class="line">    at arrayEach (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_lodash@4.17.11@lodash/lodash.js:516:11)</span><br><span class="line">    at Function.forEach (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_lodash@4.17.11@lodash/lodash.js:9344:14)</span><br><span class="line">    at Hexo._callee$ (/Users/didi/Documents/personal/xiang578.github.io/node_modules/hexo-leancloud-counter-security/index.js:83:27)</span><br><span class="line">    at tryCatch (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_regenerator-runtime@0.11.1@regenerator-runtime/runtime.js:62:40)</span><br><span class="line">    at Generator.invoke [as _invoke] (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_regenerator-runtime@0.11.1@regenerator-runtime/runtime.js:296:22)</span><br><span class="line">    at Generator.prototype.(anonymous function) [as next] (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_regenerator-runtime@0.11.1@regenerator-runtime/runtime.js:114:21)</span><br><span class="line">    at step (/Users/didi/Documents/personal/xiang578.github.io/node_modules/_babel-runtime@6.26.0@babel-runtime/helpers/asyncToGenerator.js:17:30)</span><br><span class="line">    at /Users/didi/Documents/personal/xiang578.github.io/node_modules/_babel-runtime@6.26.0@babel-runtime/helpers/asyncToGenerator.js:28:13</span><br><span class="line">    at process._tickCallback (internal/process/next_tick.js:68:7)</span><br></pre></td></tr></table></figure></p><p>JSON 在解析字符串<code>{"title":"System.out.println("hello world!");","url":"/post/hello-world.html"}</code> 时出现错误。对应的正是之前写的一篇名为 <code>System.out.println("hello world!");</code> 的文章，由于 JSON 格式中字符串是需要用<code>""</code> 修饰，导致JSON 中出现了一个 <code>"title":"System.out.println("hello world!");"</code> key-value 组合。然而实际上 JSON 只会将 <code>"System.out.println("h</code> 解析成 value，之后出现的 <code>h</code> 被当成非法字符报错。</p><p>定位问题之后，暂时修改文章的标题为 <a href="https://xiang578.com/post/hello-world.html">hello world! | 算法花园</a>，绕过部署失败。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;昨天按照 &lt;a href=&quot;https://github.com/theme-next/hexo-theme-next/blob/master/docs/LEANCLOUD-COUNTER-SECURITY.md&quot; target=&quot;_blank&quot; rel=&quot;noopener
      
    
    </summary>
    
      <category term="站务" scheme="https://xiang578.com/categories/%E7%AB%99%E5%8A%A1/"/>
    
    
      <category term="blog" scheme="https://xiang578.com/tags/blog/"/>
    
      <category term="hexo" scheme="https://xiang578.com/tags/hexo/"/>
    
      <category term="hack" scheme="https://xiang578.com/tags/hack/"/>
    
  </entry>
  
  <entry>
    <title>博客折腾记：主题更新、迁移博客到腾讯云COS以及解决百度收录</title>
    <link href="https://xiang578.com/post/use-cos-to-store-blog.html"/>
    <id>https://xiang578.com/post/use-cos-to-store-blog.html</id>
    <published>2019-05-19T07:44:09.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<p>本周有空对博客进行新一轮折腾，现在将这些尝试记下来和大家分享。</p><h3 id="主题更新">1. 主题更新</h3><p>我在 <a href="http://xiang578.com/2018/05/28/use-travis-ci-to-auto-update/">博客折腾记：使用 Travis CI 自动部署</a> 中提到将主题以 modules 的形式加入主仓库。而且现在使用的主题 git 仓库是我自己 fork 的，也有一些修改。几个天之前，hexo-theme-even 的 master 接受 <a href="https://github.com/ahonn/hexo-theme-even/pull/236" target="_blank" rel="noopener">feat: add LaTeX support by JieJiSS · Pull Request #236</a> ，完成对 LaTeX 公式的支持。所以，我需要将使用的代码和最新的代码合并。</p><p>这里使用的是 github Pull request 功能。在你自己 fork 的仓库的网页上点击 <code>new pull request</code>，然后按照下图修改。就会生成一个新的 Pull request 。 <img src="/file/15582362469640.jpg" alt="-w1009"></p><p>而且，如果你没有修改过原来的代码，PR 能自动合并。不过由于我对代码做了一些修改，会产生一些冲突，需要手动解决冲突（这里推荐使用 VS code）。出现下图的情况即成功合并两个库。 <img src="/file/15582366459115.jpg" alt="-w1046"></p><p>完成 PR 后，进入你站点下面的对应主题目录，使用 <code>git checkout master</code> 切换到主题的 master 分支，使用 <code>git pull origin master</code> 拉取最新的代码。回退到站点目录下，利用 <code>git add</code> 更新。</p><h3 id="迁移博客到腾讯云cos">2. 迁移博客到腾讯云COS</h3><p>利用腾讯云存储博客的静态文件，并配合使用 CDN 可以加快国内的访问速度。参考 <a href="https://segmentfault.com/a/1190000018752657?utm_source=tag-newest" target="_blank" rel="noopener">Hexo博客迁移之旅（Coding到腾讯云COS）+ Travis CI持续集成 - 个人文章 - SegmentFault 思否</a> 以及 <a href="https://cloud.tencent.com/developer/article/1185253" target="_blank" rel="noopener">如何在腾讯云COS部署HEXO博客 - 云+社区 - 腾讯云</a> 。</p><p>记录两个我遇到的坑。</p><h4 id="新的域名解析">新的域名解析</h4><p>完成 COS 配置后，需要将博客域名解析到腾讯提供CDN节点上的地址。</p><h4 id="添加持续集成自动发布到costravis-ci">添加持续集成自动发布到COS（Travis CI）</h4><p>为了发布到 COS，站点的 <code>_config.yml</code> 会添加下面的代码。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> <span class="attr">deploy:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">cos</span></span><br><span class="line">  <span class="attr">secretId:</span> <span class="string">XXX_ID</span></span><br><span class="line">  <span class="attr">secretKey:</span> <span class="string">XXX_KEY</span></span><br><span class="line">  <span class="attr">appId:</span> <span class="number">1252086360</span></span><br><span class="line">  <span class="attr">bucket:</span> <span class="string">blog-1252086360</span></span><br><span class="line">  <span class="attr">region:</span> <span class="string">ap-shanghai</span></span><br></pre></td></tr></table></figure><p>其中出现的 secretId 以及 secretKey 是私钥，不要在公开仓库展示。通过Travis-ci 中添加 Environment Variables 解决。</p><p>很多教程里，他们的 <code>_config.yml</code> 不会出现 secretId 和 secretKey 这两行，取而代之的是让你在 <code>.travis.yml</code> 添加几行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">script </span><br><span class="line">- hexo d</span><br><span class="line">env:</span><br><span class="line"> global:</span><br><span class="line">   - secretId: $&#123;secretId&#125; # Environment Variables 中配置</span><br><span class="line">   - secretKey: $&#123;secretKey&#125; # Environment Variables 中配置</span><br></pre></td></tr></table></figure><p>按照这样设置，build 时，出现错误提示如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123; error:</span><br><span class="line">   &#123; Code: &apos;InvalidAccessKeyId&apos;,</span><br><span class="line">     Message: &apos;The access key Id format you provided is invalid.&apos;,</span><br><span class="line">     Resource:</span><br><span class="line">      &apos;blog-1252086360.cos.ap-shanghai.myqcloud.com/2012/01/23/2011/index.html&apos;,</span><br><span class="line">     RequestId: &apos;NWNlMDU3NzlfNWI5ZDA4MDlfNWVlMF81ZWUzNTg=&apos;,</span><br><span class="line">     TraceId:</span><br><span class="line">      &apos;OGVmYzZiMmQzYjA2OWNhODk0NTRkMTBiOWVmMDAxODc0OWRkZjk0ZDM1NmI1M2E2MTRlY2MzZDhmNmI5MWI1OTQyYWVlY2QwZTk2MDVmZDQ3MmI2Y2I4ZmI5ZmM4ODFjMDU3YThkNThjZmQ1NWVkMGY2ZDBiNGM1YTEyNGIzMGM=&apos; &#125;,</span><br><span class="line">  statusCode: 403,</span><br><span class="line">  headers:</span><br><span class="line">   &#123; &apos;content-type&apos;: &apos;application/xml&apos;,</span><br><span class="line">     &apos;content-length&apos;: &apos;513&apos;,</span><br><span class="line">     connection: &apos;keep-alive&apos;,</span><br><span class="line">     date: &apos;Sat, 18 May 2019 19:05:29 GMT&apos;,</span><br><span class="line">     server: &apos;tencent-cos&apos;,</span><br><span class="line">     &apos;x-cos-request-id&apos;: &apos;NWNlMDU3NzlfNWI5ZDA4MDlfNWVlMF81ZWUzNTg=&apos;,</span><br><span class="line">     &apos;x-cos-trace-id&apos;:</span><br><span class="line">      &apos;OGVmYzZiMmQzYjA2OWNhODk0NTRkMTBiOWVmMDAxODc0OWRkZjk0ZDM1NmI1M2E2MTRlY2MzZDhmNmI5MWI1OTQyYWVlY2QwZTk2MDVmZDQ3MmI2Y2I4ZmI5ZmM4ODFjMDU3YThkNThjZmQ1NWVkMGY2ZDBiNGM1YTEyNGIzMGM=&apos; &#125; &#125;</span><br><span class="line">FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br><span class="line">TypeError: Cannot read property &apos;statusCode&apos; of undefined</span><br><span class="line">    at uploadFileToCOS.catch.then.data (/home/travis/build/xiang578/xiang578.github.io/node_modules/hexo-deployer-cos/lib/deployer.js:42:16)</span><br><span class="line">    at process._tickCallback (internal/process/next_tick.js:68:7)</span><br></pre></td></tr></table></figure><p>出现这个问题是 <code>hexo -d</code> 时，_config.yml 无法获得环境变量 secretId 和 secretKey 的。会导致没有秘钥。</p><p>参考 <a href="https://zhuanlan.zhihu.com/p/37014376" target="_blank" rel="noopener">使用 Travis CI 部署你的 Hexo 博客 - 知乎</a> ，在 .trvis.yml 文件的 <code>hexo d</code> 命令前，加入下面两行即可解决。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- sed -i &quot;s~XXX_ID~$&#123;secretId&#125;~&quot; _config.yml</span><br><span class="line">- sed -i &quot;s~XXX_KEY~$&#123;secretKey&#125;~&quot; _config.yml</span><br></pre></td></tr></table></figure><p>之后build 时，会自动利用环境变量中 secretId 和 secretKey 的值替换 <code>_config.yml</code> 文件缺省的值。</p><p>最后提供我的两份配置文件给大家参考：<a href="https://github.com/xiang578/xiang578.github.io/blob/hexo/_config.yml" target="_blank" rel="noopener">_config.yml</a>、<a href="https://github.com/xiang578/xiang578.github.io/blob/hexo/.travis.yml" target="_blank" rel="noopener">.travis.yml</a>。</p><h3 id="百度收录">3. 百度收录</h3><p>之前，我一直将博客的静态文件存储在 github 的项目中，也使用插件生成 <a href="https://xiang578.com/baidusitemap.xml">baidusitemap</a> 文件。但是由于一些不为人知的秘密，百度的爬虫实际上无法爬取 github 上的资源，导致博客最新的文章没有被收录到百度中。</p><p>而且从百度提供的抓取诊断上来看，配置腾讯云 COS 后，百度的爬虫依然访问的是 github 上的仓库。</p><figure><img src="/file/15582343082714.jpg" alt="-w558"><figcaption>-w558</figcaption></figure><p>一顿搜索之后，找到一个主动提交 hexo 博客链接至百度的插件 <a href="https://github.com/huiwang/hexo-baidu-url-submit" target="_blank" rel="noopener">huiwang/hexo-baidu-url-submit</a>。</p><p>参考 <a href="https://hui-wang.info/2016/10/23/Hexo%E6%8F%92%E4%BB%B6%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%B8%BB%E5%8A%A8%E6%8F%90%E4%BA%A4%E9%93%BE%E6%8E%A5/" target="_blank" rel="noopener">Hexo插件之百度主动提交链接 | 王辉的博客</a> 以及 <a href="https://www.jianshu.com/p/f37452d4978e" target="_blank" rel="noopener">Hexo百度主动提交链接 - 简书</a> 完成配置。</p><ul><li>安装插件 <code>cnpm install hexo-baidu-url-submit --save</code></li><li>修改根目录下面的 <code>config.yml</code> 文件，配置 baidu_url_submit 和 deploy。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">baidu_url_submit:</span><br><span class="line">  count: 100 ## 比如3，代表提交最新的三个链接</span><br><span class="line">  host: xiang578.com ## 在百度站长平台中注册的域名</span><br><span class="line">  token: your_token ## 请注意这是您的秘钥， 请不要发布在公众仓库里!</span><br><span class="line">  path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里</span><br><span class="line"></span><br><span class="line">deploy:</span><br><span class="line">- type: cos</span><br><span class="line">  secretId: XXX_ID</span><br><span class="line">  secretKey: XXX_KEY</span><br><span class="line">  appId: 1252086360</span><br><span class="line">  bucket: blog-1252086360</span><br><span class="line">  region: ap-shanghai</span><br><span class="line">- type: baidu_url_submitter</span><br></pre></td></tr></table></figure><p>上面的代码中出现一个 token，由于这是一个私有的，不能出现在 github 公开的仓库中。所以也需要 Travis-ci 中添加 Environment Variables 解决。和前文提到相同，在 <code>.travis.yml</code> 中添加 <code>- sed -i "s~your_token~${BD_TOKEN}~" _config.yml</code> 解决私钥问题。</p><p>最终在 travis-ci 中发现下面的日志即配置成功。另外一点，百度的站长平台的数据不能及时展示我们提交后的结果，需要耐心等待。</p><figure><img src="/file/15582352091163.jpg" alt="-w866"><figcaption>-w866</figcaption></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本周有空对博客进行新一轮折腾，现在将这些尝试记下来和大家分享。&lt;/p&gt;
&lt;h3 id=&quot;主题更新&quot;&gt;1. 主题更新&lt;/h3&gt;
&lt;p&gt;我在 &lt;a href=&quot;http://xiang578.com/2018/05/28/use-travis-ci-to-auto-update
      
    
    </summary>
    
      <category term="站务" scheme="https://xiang578.com/categories/%E7%AB%99%E5%8A%A1/"/>
    
    
      <category term="blog" scheme="https://xiang578.com/tags/blog/"/>
    
      <category term="travis" scheme="https://xiang578.com/tags/travis/"/>
    
      <category term="cos" scheme="https://xiang578.com/tags/cos/"/>
    
  </entry>
  
  <entry>
    <title>ImageNet Classiﬁcation with Deep Convolutional Neural Networks(AlexNet)</title>
    <link href="https://xiang578.com/post/alexnet.html"/>
    <id>https://xiang578.com/post/alexnet.html</id>
    <published>2019-05-18T12:56:43.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<h2 id="作者以及相关性">作者以及相关性</h2><ul><li>Alex Krizhevsky</li><li>Ilya Sutskever</li><li>Geoffrey E. Hinton</li><li>本文被认为是这一轮深度学习浪潮的开端</li></ul><h2 id="主题">主题</h2><ul><li>将 CNN 技术最先应用到图像识别领域，利用 CNN 参数共享的特性，减少网络的规模</li><li>解决深度网络难训练（速度慢）以及容易过拟合问题（更多数据或者网络技巧）</li></ul><h2 id="数据集与指标">数据集与指标</h2><ul><li>ImageNet LSVRC-2010 contest: 图片 1000 分类</li><li>top-1 和 top-5 错误率为指标</li></ul><h2 id="模型实验结论">模型/实验/结论</h2><h3 id="模型">模型</h3><ul><li><p>由于当时的 GPU 显存限制，无法将所有的数据加载到单独 GPU 中，作者使用两个 GPU 并行训练。</p></li><li><p>整个模型如下图所示，由 5 个卷积层以及 3 个全连接层组成。其中在 CONV3、FC1、FC2、FC3 层进行两个 GPU 的数据交互。</p><ul><li>[227, 227, 3] INPUT: 原始论文中 224 为笔误。</li><li>[55, 55, 96] CONV1: (11*11*3,96) filters, Stride 4, pad 0</li><li>[27, 27, 96] MAX POOL1: (3*3) filters, Stride 2</li><li>[27, 27, 96] NORM1: Normalization layer</li><li>[27, 27, 256] CONV2: (5*5,256) filters, Stride 1, pad 2</li><li>[13, 13, 256] MAX POOL2: (3*3) filters, Stride 2</li><li>[13, 13, 256] NORM2: Normalization layer</li><li>[13, 13, 384] CONV3: (3*3,384) filters, Stride 1, pad 1</li><li>[13, 13, 384] CONV4: (3*3,384) filters, Stride 1, pad 1</li><li>[13, 13, 384] CONV5: (3*3,256) filters, Stride 1, pad 1</li><li>[6, 6, 256] MAX POOL3: (3*3) filters, Stride 2</li><li>[4096] FC1: 两个 GPU 中的 CONV 层结果进行全连接</li><li>[4096] FC2: FC1 进行全连接</li><li>[1000] FC3: FC2 进行全连接，最后输出分类结果</li></ul></li><li><p>参数数量 60 million</p></li></ul><p><img src="/file/15580111160071.jpg"></p><ul><li>使用 ReLU 作为激活函数：比 tanh 计算开销小，以及收敛速度快。根据问题的特点选择激活函数（大模型、大数据集）</li><li>Local Response Normalization(Norm Layers)：局部响应归一化层，后来很少使用。 在经过 ReLU 作用之后，对相同空间位置上（<span class="math inline">\({b_{x,y}}\)</span>）的相邻深度（<span class="math inline">\({b^j}\)</span> ）的卷积结果做归一化。n 指定相邻卷积核数目，N 为该层所有卷积的数目。<span class="math inline">\({k, n, \alpha, \beta}\)</span> 都是超参数。本文使用 <span class="math inline">\({k=2, n=5, \alpha=10^{-4}, \beta = 0.75}\)</span>, 分别降低 top-1 和 top-5 错误 1.4% 和 1.2%</li></ul><p><span class="math display">\[b_{x, y}^{i}=a_{x, y}^{i} /\left(k+\alpha \sum_{j=\max (0, i-n / 2)}^{\min (N-1, i+n / 2)}\left(a_{x, y}^{j}\right)^{2}\right)^{\beta}\]</span></p><ul><li>Pooling：s=2 &lt; z=3，有部分重叠，作者通过实验发现这种方法可以更好地避免过拟合。</li><li>data augmentation：<ul><li>对图像进行裁剪以及翻转，扩大数据。这种策略对测试带来影响，测试时裁剪出图片四个角落以及中间部分，得到 5 张图片，另外翻转得到 5 张图片，最后分类结果又这 10 图片的平均得分确定。</li><li>利用 PCA 改变 RGB 通道的强度。</li></ul></li><li>Dropout：每次训练的时候，从模型中 sample 出一个小的模型，减少过拟合。</li></ul><h3 id="实验">实验</h3><ul><li><p>参数：dropout 0.5，batch size 128， SGD Momentum 0.9， Learning rate 1e-2 reduce by 10，L2 weight decay 5e-4</p></li><li><p>测试集上结果 <img src="/file/15581816832571.jpg"></p></li><li><p>取出 CONV1 相关的 filters卷积侧重点不同，GPU1 颜色无关，GPU2 颜色相关。多次实验发现都存在这种现象，说明使用多个 GPU 训练是必要的，模型可以捕捉更多信息。 <img src="/file/15581833748303.jpg"></p></li><li><p>取所有最后一个隐层向量，找到与测试图片欧拉距离最小的训练图片（下图中第一列为测试图片，之后几列是欧拉距离最小的训练集中图片）。肉眼可以发现，同一分类的图片有很大关联性。证明模型能学习图片之间的关系。 <img src="/file/15581820979738.jpg"></p></li></ul><h3 id="结论">结论</h3><ul><li>通过移除 AlexNet 网络中的某几层发现错误率均有提高，这个网络时必要以及有效的。</li><li>文章中作者通过大量的实验确定模型的细节问题，值得我们学习。</li><li>当时的 GPU 限制作者的想象力……</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;作者以及相关性&quot;&gt;作者以及相关性&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alex Krizhevsky&lt;/li&gt;
&lt;li&gt;Ilya Sutskever&lt;/li&gt;
&lt;li&gt;Geoffrey E. Hinton&lt;/li&gt;
&lt;li&gt;本文被认为是这一轮深度学习浪潮的开端&lt;/li&gt;

      
    
    </summary>
    
      <category term="机器学习" scheme="https://xiang578.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="cnn" scheme="https://xiang578.com/tags/cnn/"/>
    
      <category term="alexnet" scheme="https://xiang578.com/tags/alexnet/"/>
    
  </entry>
  
  <entry>
    <title>2018 探索</title>
    <link href="https://xiang578.com/post/2018.html"/>
    <id>https://xiang578.com/post/2018.html</id>
    <published>2019-04-10T04:40:45.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>全文混乱。拖了 4 个月之后，强行完结。</p></blockquote><h2 id="毕业">毕业</h2><p>2018 最大的一件是自己终于艰难地从学校毕业。本来在学校属于 easy 模式，原本以为毕业很轻松。不过出于一些原因，比其他人多待一个月才拿到毕业证书，给我不太美好的大学生涯又多添几份痛苦。本来还准备写篇文章来总结一下大学生涯，拖到现在毕业都快一周年，也只能当成是毕业一周年的回忆文章。</p><h2 id="工作">工作</h2><p>毕业之后，用我外婆说的一句话“一个人拉着两个行李箱就去工作了”。误打误撞和机器学习挂上一些关系。每天属于虽然工作很开心，但是好像没有干什么事情的状态。更多地吐槽也准备写在工作一周年的文章中。</p><h2 id="自我管理">自我管理</h2><p>这个概念是年初感觉自己太混乱时提出来的，如果成为更好的自己。一年来有过很多想法和实践，但是现在还探索出来完整的系统。有机会再写。</p><h2 id="年度阅读">年度阅读</h2><p>说来惭愧，今年没有读多少本书，而且绝大部分都是在没有毕业时候读的。工作之后，完整看完地也只有一本《九败一胜》。这本书讲的是王兴的创业故事，总的感受是创业维艰。感觉王兴是为了创业而生的人，有知识基础，又有经济基础。在多次创业之后，培养了商业上的灵敏，管理上的艺术。最终能在千团大战中走出来，成就今天的美团帝国。可惜这个冬天，美团有些艰难，脉脉上给予他裁团（裁员，特别是应届生）、C团（绩效打 C，逼你走）的名声。比起王兴的故事，我更感兴趣的是程维创立滴滴的故事，不知道什么时候可以读到。</p><p>说回来在读过的书中，最推荐 <a href="https://book.douban.com/subject/26835090/" target="_blank" rel="noopener">软技能</a>，之前也写过简单的<a href="https://xiang578.com/2018/05/28/soft-skills/">介绍</a>。用时髦的话来说，这本书教你成为一个斜杠青年。在基础的工资外，还有通过其他渠道有第二职业的收入，最后是睡后收入（表名上说的是睡觉时候获得的收入，第二层含义是一次生产，可以多次贩卖）。后来想想，自己可以二次出售什么？无法是什么时间管理、知识管理、理财、读书、写作之类的烂大街的东西。所以，自己还是需要加强抗击职业风险的能力，尽快找到自己的第二职业收入。</p><p>另外，自己也进行了一些主题阅读。年初的时候，对时间管理和知识管理感兴趣。读过<a href="https://book.douban.com/subject/25872118/" target="_blank" rel="noopener">Evernote 100个做笔记的好方法</a>、<a href="https://book.douban.com/subject/24524405/" target="_blank" rel="noopener">Evernote超效率数字笔记术</a>、<a href="https://book.douban.com/subject/26809387/" target="_blank" rel="noopener">印象笔记留给你的空间</a>、<a href="https://book.douban.com/subject/26801390/" target="_blank" rel="noopener">有道云笔记：记录，成为更好的自己</a>、<a href="https://book.douban.com/subject/4630664/" target="_blank" rel="noopener">你的知识需要管理</a>，看完这些书多少有些收获，但也没有完全解答我的疑问，说回来，也不太推荐你们去看。不过，时间管理方面的两本书，<a href="https://book.douban.com/subject/3558629/" target="_blank" rel="noopener">小强升职记</a>和<a href="https://book.douban.com/subject/26612471/" target="_blank" rel="noopener">搞定Ⅰ</a>，却是五星推荐，看一看，多少能提高一些工作效率。</p><h2 id="年度观影">年度观影</h2><p>今年看过的电影倒是比书多一些。不过，其中好多都是漫威的超级英雄片。自己感觉漫威伟大的地方在于创造了一个包括神话、物理、外星文明的电影宇宙，这个宇宙也许会成为我们这一代人的回忆。</p><p>说回来，今年看过的片子中，最推荐的是<a href="https://movie.douban.com/subject/6874741/" target="_blank" rel="noopener">无问西东</a>。这部片子讲述了不同时期 4 个不同年代清华学子关于选择的故事，也许是因为没有他们这样的大学经历才会嫉妒。看完片子后，还抄录一些台词，大概能更加清晰的表达电影对我的影响。</p><p>吴岭澜（文科很好，理科很差）面对梅校长时候询问为什么不去读文科时的回答。 &gt; 因为最好的学生都读实科 我只知道，不管我将来做什么 在这个年纪，读书，学习都是对的 我何用管我学什么？ 每天把自己交给书本，就有种踏实</p><p>吴岭澜重新找到自己的目标之后，成为了清华大学的一名教授。在西南联大给学生上课时回忆自己的大学时光： &gt; 当我在你们这个年纪，有段时间，我远离人群，独自思索，我的人生到底应该怎样度过？某日，我偶然去图书馆，听到泰戈尔的演讲，而陪同在泰戈尔身边的人，是当时最卓越的一群人，这些人站在那里，自信而笃定，那种从容让我十分羡慕。而泰戈尔，正在讲“对自己的真实”有多么重要，那一刻，我从思索生命意义的羞耻感中，释放出来。原来这些卓越的人物，也认为花时间思考这些，谈论这些，是重要的。今天，我把泰戈尔的诗介绍给你们，希望你们在今后的岁月里，不要放弃对生命的思索，对自己的真实。</p><p>对吴岭澜的总结： &gt; 梅校长说：“人把自己置身于忙碌当中，有一种麻木的踏实，但丧失了真实，你的青春也不过只有这些日子。” 什么是真实？ 你看到什么，听到什么，做什么，和谁在一起 有一种，从心灵深处，满溢出来的不懊悔，也不羞耻的平和与喜悦</p><p>后来吴岭澜领悟到了： 看到和听到的，经常令你们沮丧，世俗是这样强大，强大到生不出改变它们的念头。可是如果有机会提前了解了你们的人生，知道青春也不过只有这些日子，不知你们是否还会在意的，那些世俗让你们在意的事情，比如占有多少，才更荣耀，拥有什么，才能被爱。 等你们长大，你们因绿芽冒出土地而喜悦，会对出生的朝阳欢呼雀跃，也会给别人善意和温暖，但是却会在赞美别的生命的同时，常常，甚至永远忘了自己的珍贵。愿你在被打击的时，记起你的珍贵，抵抗恶意；愿你在迷茫时，坚信你的珍贵，爱你所爱，行你所行，听从你心，无问西东。</p><p>富家子弟沈光耀放弃学业，决定参加飞行队时，母亲不远万里来联大劝他。</p><blockquote><p>“当初你离家千里，来到这个地方读书，你父亲和我都没有反对过，因为，是我们想你，能享受到人生的乐趣，比如读万卷书行万里路，比如同你喜欢的女孩子结婚生子。注意不是给我增添子孙，而是你自己，能够享受为人父母的乐趣，你一生所要追求的功名利禄，没有什么是你的祖上没经历过的，那些只不过是人生的幻光。我怕，你还没想好怎么过这一生，你的命就没了啊！”</p></blockquote><p>同学在他牺牲后，去看望沈母时，屏幕上展现出一幅对联：三代五将护国定疆青史留正气，六韬三略擅用筹边御旨赞英豪。</p><p>这部电影的彩蛋标题是致敬时代的风骨，快速回顾在电影中出现过的时代名人。可惜自己没有认出多少个，真是悲哀。</p><h2 id="后记">后记</h2><p>这篇文章写的有点杂，我只是看着 MWeb 中的存稿有点多，趁着这次机会消灭一些，来年有机会写些新的东西。</p><p>于北京回龙观</p><p>其他文章：</p><ul><li><a href="https://xiang578.com/post/2017.html">2017 迷茫</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;全文混乱。拖了 4 个月之后，强行完结。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;毕业&quot;&gt;毕业&lt;/h2&gt;
&lt;p&gt;2018 最大的一件是自己终于艰难地从学校毕业。本来在学校属于 easy 模式，原本以为毕业很轻松。不过出于一些原因，比其他
      
    
    </summary>
    
    
      <category term="life" scheme="https://xiang578.com/tags/life/"/>
    
      <category term="book" scheme="https://xiang578.com/tags/book/"/>
    
      <category term="movie" scheme="https://xiang578.com/tags/movie/"/>
    
  </entry>
  
  <entry>
    <title>每周分享第 11 期</title>
    <link href="https://xiang578.com/post/week-issues-11.html"/>
    <id>https://xiang578.com/post/week-issues-11.html</id>
    <published>2019-03-16T12:56:43.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这里记录过去一周，我看到的值得分享的东西，每周六不定时更新。</p></blockquote><h2 id="观点">观点</h2><ul><li>美团和滴滴为什么要互相开展对方的业务：<ol type="1"><li>我记得罗振宇在某一年时间的朋友中提到一个观点：O2O 领域会出现一个超级公司，业务横跨所有场景。</li><li>从技术角度分析，外卖中比较难的点在于分单、时间估计以及路径规划。这也是出行服务中的技术难点。不过各有侧重，外卖中路径规划相当于最多不超过 20 个点（10 个商家处取餐，10 个顾客中送餐）的 TSP 问题。出行服务最关键的是如何有效的获取道路信息。（我有一个观点，人是有主观能动性的，会抄各种小道）</li><li>这两个服务都严重依赖地推服务，所以双方本身都有一支庞大的城市地推人员。我想开展不同业务的切换难度应该会小一些。</li></ol></li></ul><h2 id="读书刻意练习">读书《刻意练习》</h2><p>听这个名字很容易认为是一本鸡汤书，英文小标题中提到 New science of Experitse。本书打破的是之前很流行的 1 万小时天才理论，这个理论认为很多天才之所以是天才是他们的技能经过长时间的训练，有量变引起质变。新的研究发现，学习的本质是在大脑中建立心理表征，它是一种长时记忆单元，也是我们习得技能的结果。刻意练习就是如何高效地获得这个心理表征。鉴于这是一本脑科学的书，方法是否正确还应该是自己亲身体验才能知道。</p><h2 id="文章">文章</h2><ul><li><a href="https://sspai.com/post/46056" target="_blank" rel="noopener">经过一年的思考，我重新梳理了我的印象笔记使用方法 - 少数派</a>：不知道为什么，我对这类文章特别地喜欢。这篇文章带来的新意是对知识的六种分类，之前我自己没有考虑过。不要过度沉溺于研究工具，而忘记学习的初心。</li><li><a href="https://www.zhihu.com/question/280483874/answer/420024531" target="_blank" rel="noopener">教授说没有写过一千行代码就别想上大公司，这种说法对吗？ - 知乎</a>：之前看到这个问题就想直接喷，写一千行代码怎么去大公司。看完其他人的回答，才发现又一次陷入到了思维定势。从数学角度来说，写一千行代码去大公司是一个必要不充分条件，去大公司确实需要写代码，一千行是被包括的，但可能远远不够。</li><li><a href="https://blog.yitianshijie.net/2017/09/14/chinese-translation-of-steve-jobs-recording-on-iphone-x-event/" target="_blank" rel="noopener">iPhone X 发布会乔布斯录音的中译（或当代汉语现状） – 一天世界</a>：一段英文白话翻译以及文言翻译对比，又一次体会到古典之美。<ul><li>There’s lots of ways to be as a person, and some people express their deep appreciation in different ways. But one of the ways that I believe people express their appreciation to the rest of humanity is to make something wonderful and put it out there. You never meet the people, you never shake their hands, you never hear their stories or tell yours. But somehow in the act of making something with a great deal of care and love, something’s transmitted there. And it’s a way of expressing to the rest of our species our deep appreciation. So we need to be true to who we are and remember what’s really important to us. That’s what’s gonna keep Apple, Apple, is if we keep us, us.</li><li>「李如一」译文：人生而有别，感恩之心亦可谓十人十色。创造神奇，示之于人，此为对人性感恩之一种也。彼二人或未曾握手相见，对各自生平事故复无相闻，惟细巧体贴之创造即足以千里传音。此即吾等人类传递感恩之心之法门也。故人必诚于其本色，忠于其所信。林檎之为林檎，端赖吾辈不忘初心也。愿与诸君共勉。</li><li>「<span class="citation" data-cites="东莞大唐和尚">@东莞大唐和尚</span>」译文：人与人的生活方式千差万别，表达感恩的方式也是多种多样。但我认为，做出一件绝妙的东西，才是向这个世界表达感恩的最最深刻的方式。你没见过那些人，没跟他们握过手，你没听过他们的故事，也没跟他们讲过自己的经历，但就是通过你倾注心血做出的这样一件东西，你传达给了他们一些东西。这是向其他人表达我们感激的最深刻的方式。我们需要真诚地面对自我，永远记住对自己最重要的东西是什么。苹果之所以是苹果，我们之所以是我们，正在于此。</li></ul></li></ul><h2 id="视频">视频</h2><ul><li><a href="https://www.bilibili.com/bangumi/media/md97952/" target="_blank" rel="noopener">人生一串 _ 纪录片 _ bilibili _ 哔哩哔哩弹幕视频网</a>：属于国人的深夜食堂，再搭配上神级文案，完美展示烧烤江湖。</li></ul><h2 id="后记">后记</h2><p>这半年自己写的东西有点少，从第 10 期到这一次拖了好久。最初，是在阮一峰的鼓舞下开始这种形式的分享。不过后来由于种种原因，又展现出自己的本质。有些事情还是要坚持的，所以将这些存货发布出来。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;这里记录过去一周，我看到的值得分享的东西，每周六不定时更新。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;观点&quot;&gt;观点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;美团和滴滴为什么要互相开展对方的业务：
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;我记得罗振宇在某
      
    
    </summary>
    
      <category term="每周分享" scheme="https://xiang578.com/categories/%E6%AF%8F%E5%91%A8%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>2018 年消费指南</title>
    <link href="https://xiang578.com/post/2018-consumer-report.html"/>
    <id>https://xiang578.com/post/2018-consumer-report.html</id>
    <published>2019-01-13T11:05:14.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<p>去年在总结中提到了一些知识付费的内容，今年将内容扩展，和大家分享我在这一年购买的实物以及虚拟产品。</p><h2 id="实体购物">实体购物</h2><p>工作之后，感觉自己每个月留不下多少钱，很大一部分用来购买一些号称提高工作效率有关的物件。现在毕竟钱都花出去了，至少要装模作样地总结它们给我带来的提升。</p><h3 id="键鼠">键鼠</h3><p>入职之后，地主只给我提供了一把锄头（Macbook Pro 13 with touchbar），长时间在蝴蝶键盘上敲击不是很愉悦的感觉。所以自己产生了购买键盘和鼠标的念头。</p><p>众所周知，机械键盘是码农的标配，用手指在键盘上噼里啪啦快速敲击，想想就有画面感。之前在上学的时候，我拥有一把 IKBC G87 的青轴键盘。IKBC 的优点在于价格便宜，不过和同学的 Filco 圣手对比，手感不是那么的清脆。而且本着一步到位的想法，这次准备购买的键盘可以贵一些。再加上一些其他的条件，将自己的选择限定在了 Filco 和 HHKB 上。众所周知，HHKB 的价格差不多可以买两个 Filco。最后是遇到了少数派的优惠活动，才痛下决心买了一个 HHKB Professional BT（其实是多送了少数派的贴纸而已）。</p><figure><img src="/file/15473651233100.jpg" alt="HHKB"><figcaption>HHKB</figcaption></figure><p>评价 HHKB 最好的方式是引用其创始人和田英一下面这一段话：</p><blockquote><p>美国西部的牛仔们，会将死去的马儿留在原地，但是仍然会扛着马鞍长途跋涉，穿越一望无垠的沙漠。因为马儿是消耗品，而马鞍却是与人体融合在一起的“知己”。我们要有这样的观念：现在，电脑是消耗品，键盘却是传递情感，陪伴我们一生的“挚友”。</p></blockquote><p>HHKB 给人最大的感觉就是与众不同，一共只有 60 个按键。整个键盘长度和一张 A4 纸相当。看下面的布局图不难发现：</p><ol type="1"><li>没有 F1-F12 功能按键</li><li>没有方向键</li><li>Caps 键的位置上是 Control 键</li></ol><figure><img src="/file/HHKB_Pro2_Layout.jpg" alt="HHKB_Pro2_Layout"><figcaption>HHKB_Pro2_Layout</figcaption></figure><p>咋一看，很难满足一般的工作需求。但是经过对工作方式的一些调整，可以很好的完成日程任务，而且键盘的手感不错（从 v2 上看到的形容是少女酥胸的手感，具体是不是我也没有体验过），长时间敲击没有疲劳感。我的编程主要在服务器上用 vim 完成，所以 hjkl 才是我的方向键，而且我也在 Jetbrain 的编辑器中安装了 vim 插件。对于其他情况下，使用 Karabiner Elements 对键盘进行一些改造（按住 Control 开启 vi 模式，hjkl 变成方向键），最后还可以用 Mac 系统自带的一些文本编辑相关的快就键。</p><figure><img src="/file/Jietu20180823-223800.jpg" alt="Karabiner_Elements"><figcaption>Karabiner_Elements</figcaption></figure><p>有了键盘之后，不能没有鼠标。其实这里面也有两个选择：罗技 的 MX Master 2 和苹果的触摸板。不得不说， mnp 自带的触摸板用起来非常的爽快，但是单独购买触摸板价格也很感人，提前退出了购买范围。趁着双十一，在京东买下了 MX Master 2。</p><figure><img src="/file/15473661736323.jpg" alt="MX Master 2"><figcaption>MX Master 2</figcaption></figure><p>看上面的图片可以知道，这是一款人体工程学的鼠标，而且有一些按键可以编程（配合软件）。支持蓝牙以及接受器连接，可以记忆三个设备。据说，还实现了在一台电脑上复制，再另外一台电脑上粘贴。总体用下来也是中规中矩，除了中间的滚轮阻尼感有点差之外（侧边的滚轮手感很好，但是不能修改成上下滚动的效果），也没有太多缺点。</p><h3 id="bose-qc-35-二代">Bose QC 35 二代</h3><p>购买降噪耳机多少是出于无奈，离开学校的图书馆之后，很少能找到一个安静的地方，让自己静下心来干一些事情。特别是在开放的办公室中，不仅有其他同事的讨论声，还有空调的噪音。带上降噪耳机，在放上一曲喜欢的音乐，就感觉来到了另外一个世界。之前在知乎上看到的一个评价正好能形容这种感觉：</p><blockquote><p>有多安静我来描述一下，孩子数学成绩不好，你在银行做经理，维护客户关系，不上不下，有房贷和车贷，每月按揭五千。你老婆在市人民医院做护士，她妈有尿毒症透析多年，她不爱你。你年轻的时候觉得能成一番事业，但现在也就这样，朋友们混的都比你好，你下班在车库停稳车，关掉引擎，呜一声安静了下来。太安静了，你生命中少有这么安静的时刻，你打算发十分钟呆再上楼吃饭。 以上就是 BOSE QC 35 的降噪效果测评。</p></blockquote><p>所以充分证明，现在的耳机评测多么注重编故事的能力。说回来，带上耳机之后，空调之类的噪音基本上会被隔绝，其他人声只是轻微的减弱，就像他们在远处处聊天。总体来说，这副耳机达到了我的预期，也算是一笔合理消费。</p><h3 id="米家宇宙">米家宇宙</h3><p>用这里来调侃一下，小米出的那么多智能家电。自己入手了米家台灯和小饭煲，搭配米家的 APP ，可以实现晚上当你拖着身体回来时有一盏灯为你亮起，清晨又有一锅粥等你去品尝。最近，米家 APP 通过捷径配合 Siri 使用，大大扩展了便利程度。未来真的快要来了。</p><figure><img src="/file/15473720711543.jpg" alt="mijia"><figcaption>mijia</figcaption></figure><h2 id="年度虚拟产品">年度虚拟产品</h2><p>与上面提到的实体产品相反的，就是虚拟产品，比如软件、文章、教程、视频等。用虚拟产品更好的总结这些消费的特点。其实很多人会觉得这些东西不值得花钱，网上找盗版的即可。但自己赞同一个观点，给优秀的内容付费，才能激励作者分享更多的知识。</p><h3 id="订阅服务">订阅服务</h3><p>在这一年中持续付费的产品有滴答清单、印象笔记、SetApp。滴答清单是最早购买的 GTD 软件，对于初学者来说，这是一个大而全的软件，从清单、日历到番茄时间应有尽有。不过，我没有打算继续在新的一年为它付费，我对 GTD 软件的要求是有强大的过滤功能，而不是那一些花里胡哨的噱头功能。印象笔记是自己选择的主力笔记软件，之前使用为知笔记，但是他在 Mac 上的功能很少，也很久没有大的更新了，而印象笔记特别是在中国区独立之后，有很多大的动静。</p><p>Setapp 是一个软件集中订阅服务，简单来说，你订阅了这个服务，可以使用很多需要购买的 Mac App。自己目前常用的有 Moneywiz（记账软件，mac 和 ios 都可以使用）、Timing（自动记录 Mac 上软件使用时间，可以看成是一个统计工作效率的软件）、Bartender（隐藏状态栏，看起来更加清爽）、iStat Menus（在状态栏显示网速、cpu使用率等系统状态）、MarginNote（比较强大的 PDF 阅读软件）、Ulysses（Markdown 写作软件）。除此之外，SetApp 还提供了 100 多款软件，总的来说是超值的服务。</p><figure><img src="/file/15473675744474.jpg" alt="-w1252"><figcaption>-w1252</figcaption></figure><h3 id="买断服务">买断服务</h3><p>相比起付费服务，直接买断的软件就显得有点少。其中的原因有很多，最重要的是很多国外软件一次性买断价格是参考国外的物价，也许对于他们来说是一顿饭的价格，对应到国内就是好几百。</p><p>MacOS 上购买了 MWeb 3，也就是现在使用的 Markdown 软件。从二代开始入手使用，用来写一些文章的草稿。另外一点，用来管理博客文档也比较方便，可以一键将文章中出现的本地图片上传到图床。不过，上面提到 SetApp 中提供了更强的 Ulysses，也许明年的总结我会用 Ulysses 完成。</p><p>iOS 中，主要购买的是一些工具。Cloud Speed，测试不同国外云服务商的不同机房的速度，买了之后没有想象中的那么好。Taskmator，搭配 Mac 上的 Taskpaper 使用，之前想用他来做任务管理，不过后来放弃了。MoneyWiz 2，超值的记账软件，帮我养成了记账的习惯。之前用过网易有钱，无法忍受他的理财社区而卸载了。无相，一款神奇的浏览器，你可以指定一些其他网站的 CSS 样式（软件中有一个商店可以下载 CSS 文件），从而提升阅读体验，间接实现去除页面上的广告……</p><h3 id="知识付费">知识付费</h3><p>罗振宇在 2016 年提出知识付费元年，可从我的角度来说，2018 才是我的知识付费元年。今年主要在两大平台进行内容消费，闲鱼以及少数派。</p><p>对的，你没有看错，闲鱼是我上半年的一个主要消费场所。有一句话，评价一个知识付费好不好，看它在闲鱼上有没有买就可以了。闲鱼上有很多倒卖的人，很可能是 N 道贩子，主要是通过百度云进行交易。比起原生的，体验是非常差的（得到的文章是长图片形式），胜在价格便宜（一两块到十几块不等）。可以用来简单判断一下内容，再决定是否需要去原网站购买。回过头来看，自己购买的绝大部分课程内容还静静地躺在百度云中……但也发现了一个精品课程，小能熊——陈华伟的《知识管理训练营》，这里面讲了很多老师自己使用 Mac 和 iPhone 进行知识管理的方法和体会。对于不是高阶的用户很是值得一看，原价是 99 元非常值得（可以在印象笔记公众号中找到）。我也做了一些笔记，一直比较忙，没有时间整理分享。搜索了一个其他人的笔记，大家可以看一下了解 <a href="https://www.jianshu.com/p/25b40b5c4d2b" target="_blank" rel="noopener">21天知识管理训练营总结【笔记版1.0】 - 简书</a></p><figure><img src="/file/15473703471065.jpg" alt="课程大纲"><figcaption>课程大纲</figcaption></figure><p>至于在少数派中，就花了很多钱够买其中的专栏。少数派是我看了好几年的一个数字资讯网站，他们的口号是「少数派致力于更好地运用数字产品或科学方法,帮助用户提升工作效率和生活品质」。自己购买了他们的会员通讯 <a href="https://sspai.com/series/9" target="_blank" rel="noopener">Power+ 1.0</a> 以及还在持续更新中的 <a href="https://sspai.com/series/70" target="_blank" rel="noopener">Power+ 2.0</a>，具体的内容介绍可以查看这两个网页。如果你也是那种喜欢折腾软件的人，这个东西非常超值。任务管理系列（<a href="https://sspai.com/series/69" target="_blank" rel="noopener">用 OmniFocus 3 搭建任务管理系统</a>、<a href="https://sspai.com/series/1" target="_blank" rel="noopener">用更现代的方式做任务管理</a>、<a href="https://sspai.com/series/22" target="_blank" rel="noopener">TaskPaper 使用指南</a>），其实购买这三个完全是没有必要，你喜欢哪一个软件做 GTD，直接购买对应的教程就好了。最后也很推荐的是 <a href="https://sspai.com/series/3" target="_blank" rel="noopener">从零开始做好个人记账</a>，教你使用 Moneywiz 记一手明白账（原理通用，也可以使用其他软件。）</p><figure><img src="/file/15473712908061.jpg" alt="sspai"><figcaption>sspai</figcaption></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;去年在总结中提到了一些知识付费的内容，今年将内容扩展，和大家分享我在这一年购买的实物以及虚拟产品。&lt;/p&gt;
&lt;h2 id=&quot;实体购物&quot;&gt;实体购物&lt;/h2&gt;
&lt;p&gt;工作之后，感觉自己每个月留不下多少钱，很大一部分用来购买一些号称提高工作效率有关的物件。现在毕竟钱都花出去了，至
      
    
    </summary>
    
      <category term="生活志" scheme="https://xiang578.com/categories/%E7%94%9F%E6%B4%BB%E5%BF%97/"/>
    
    
      <category term="life" scheme="https://xiang578.com/tags/life/"/>
    
  </entry>
  
  <entry>
    <title>博客折腾记：修复七牛云测试域名失效问题</title>
    <link href="https://xiang578.com/post/fix-qiniu-test-url-error.html"/>
    <id>https://xiang578.com/post/fix-qiniu-test-url-error.html</id>
    <published>2018-12-20T19:39:14.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<p>毕业之后开始工作快要 5 个月了，然后也快有 3 个月没有更新博客。其实文本编辑器中还有很多的草稿，但是一直没有力量驱动自己完结他们，并且分享出来。另外，这一段时间也不是完全没有分享。在这个页面的上方有一个 <code>Tech</code> 的标签，可以连接到我新搭的博客。受限于当前使用的 hexo 主题无法配置 latex 数学公式，所幸新开博客分享算法学习的笔记。大家感兴趣的可以访问一下，不过也没有太多的内容。</p><p>这次在博客公告中要告诉大家的确是另外一件事情。屋漏偏风连夜雨，不知道从什么时候开始，七牛云开始图片使用测试域名，毫无疑问这个博客的图片都挂了。自己也一直没有动力修复，让这一段时间访问我博客的小伙伴受累了。</p><p>今天研究了一下如何修复这个图床问题。官方有一个帮助页面<a href="https://developer.qiniu.com/fusion/kb/1322/how-to-configure-cname-domain-name" target="_blank" rel="noopener">如何配置域名的 CNAME - 七牛开发者中心</a>，大概就是你的存储空间之前有一个测试域名（比如我的是 7xkpe5.com1.z0.glb.clouddn.com），现在不允许通过测试域名访问图片，需要绑定一个备案过的域名才可以。所以我们需要两个步骤完成改造：首先，给空间绑定一个域名（比如现在使用的是 media.xiang578.com ）；最后，在域名解析平台添加一个 CNAME，将你指定的域名转发到七牛的记录上。</p><p>完成上一步后，图片还是不能正常显示。因为之前的文章中，图片的链接都是以测试域名开头的，比如<code>7xkpe5.com1.z0.glb.clouddn.com/15283589946007.jpg</code> ，现在我们要将它改成 下面的形式 <code>media.xiang578.com/15283589946007.jpg</code>。简单的方法是打开文本编辑软件，然后使用查找替换功能，一个一个文件处理。显然这很无聊，而且进入 <code>source/_posts</code> 目录下利用 <code>grep 7xkpe5 *.md | wc</code> 统计了一个，我大概需要修改的有 142 处。</p><figure><img src="/file/15453335377518.jpg" alt="需要替换的字符串"><figcaption>需要替换的字符串</figcaption></figure><p>幸运地是 linux 系统下有两大文本处理利器 <code>sed</code> 和 <code>awk</code>。我们使用 <code>sed</code> 可以将一个字符串转换为另外一个字符串。网上搜索了一下用法，很快写了出来</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i -r "s/7xkpe5\.com1\.z0\.glb\.clouddn\.com/media\.xiang578\.com/g" *.md</span><br></pre></td></tr></table></figure><p>这条命令中原始形态可以表示为 <code>sed 's/原字符串/替换字符串/g'</code>。其中参数 <code>-i</code> 代表替换文件中的所有匹配项，<code>-r</code> 代表批量替换支持扩展表达式。在原字符串和替换字符串中都出现了 <code>\.</code>，应为 <code>.</code> 在 <code>sed</code> 命令中代表匹配任意单个字符，加上转移字符后可以代表它本身。最后 <code>*md</code> 代表对目录下的 <code>md</code> 文件进行处理。</p><p>运行完成之后，我们在统计一下测试域名和正式域名的数量，可以发现完美的解决了这个问题，图片又能正常显示。</p><figure><img src="/file/15453344578555.jpg" alt="修改后"><figcaption>修改后</figcaption></figure><p>所以，写下今天这一篇博客一切都是因为贫穷。如果有钱直接在主机上放置图片，有带宽提供出来访问，也就不会依赖七牛云了……</p><hr><p> 2019.11.09</p><p>为了减少博客依赖服务，参考 <a href="https://zealot.top/%E5%9B%BE%E5%BA%8A%E4%BB%8E%E4%B8%83%E7%89%9B%E4%BA%91%E8%BF%81%E7%A7%BB%E5%88%B0%E8%85%BE%E8%AE%AFCOS.html" target="_blank" rel="noopener">图床从七牛云迁移到腾讯COS折腾笔记 | 思想就是武器</a> 将所有的图片全部从七牛上下载，利用 COS 存储。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;毕业之后开始工作快要 5 个月了，然后也快有 3 个月没有更新博客。其实文本编辑器中还有很多的草稿，但是一直没有力量驱动自己完结他们，并且分享出来。另外，这一段时间也不是完全没有分享。在这个页面的上方有一个 &lt;code&gt;Tech&lt;/code&gt; 的标签，可以连接到我新搭的博客
      
    
    </summary>
    
      <category term="站务" scheme="https://xiang578.com/categories/%E7%AB%99%E5%8A%A1/"/>
    
    
      <category term="blog" scheme="https://xiang578.com/tags/blog/"/>
    
      <category term="hack" scheme="https://xiang578.com/tags/hack/"/>
    
  </entry>
  
  <entry>
    <title>字体的重要性</title>
    <link href="https://xiang578.com/post/ImportanceOffont.html"/>
    <id>https://xiang578.com/post/ImportanceOffont.html</id>
    <published>2018-09-03T23:41:14.000Z</published>
    <updated>2019-12-02T02:24:36.168Z</updated>
    
    <content type="html"><![CDATA[<h1 id="字体的重要性">字体的重要性</h1><p>最近开始工作，基本上都和终端打交道，碰到几个误认字符的尴尬场面，记录一下。</p><p>第一个遇到的问题发生在输入账户密码时，公司发的小册子上写的密码大概形式如<code>xxxxxi|6xxx</code>。由于打印密码的字体是黑体，难免产生疑问 <code>|</code> 到底是 <code>I</code> 还是 <code>l</code>？观察到的细节是 <code>|</code> 这个字符下面比其他的字符长，不过由于之前很少在密码中使用过这个字符，所以以为这个细节是区分<code>I</code> 和 <code>l</code> 的。在密码错误 n 次后，眼光扫到键盘才发现回车键上面的 <code>|</code> 键。</p><p>第二个遇到的问题是在终端中，公司的堡垒机登陆比较复杂，一般都会写脚本来快速登陆。写完之后，运行指令的格式为</p><blockquote><p>jump ip 'auth'</p></blockquote><p>其中的 'auth' 部分为调用另外一个脚本生成一个二次验证的并作为 jump 命令的参数。其中这个 ' 符号被我认为是引号，后来查阅相关的 shell 命令（相关文章参考<a href="https://blog.csdn.net/a515983690/article/details/51554297/" target="_blank" rel="noopener">linux下命令执行结果作为其他命令输入参数 - CSDN博客</a>），才明白为反引号（一般位于ESC 的下方）。</p><p>说完这两个问题，回到主题，每天和字母打交到，选着一款合适的字体是非常重要的。推荐一款我在几年前就使用的编程字体——<a href="https://github.com/source-foundry/Hack" target="_blank" rel="noopener">Hack: A typeface designed for source code</a>。</p><figure><img src="/file/15348602272400.png" alt="Hack 字体示意"><figcaption>Hack 字体示意</figcaption></figure><p>上图就是这款字体的示意，最喜欢的点是 <code>0</code> 中间有一个小竖点，非常的传神。 以至于现在 IDE 中的 0 不是想上面这样处理，我都感觉不会编程了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;字体的重要性&quot;&gt;字体的重要性&lt;/h1&gt;
&lt;p&gt;最近开始工作，基本上都和终端打交道，碰到几个误认字符的尴尬场面，记录一下。&lt;/p&gt;
&lt;p&gt;第一个遇到的问题发生在输入账户密码时，公司发的小册子上写的密码大概形式如&lt;code&gt;xxxxxi|6xxx&lt;/code&gt;。由于打
      
    
    </summary>
    
      <category term="程序园" scheme="https://xiang578.com/categories/%E7%A8%8B%E5%BA%8F%E5%9B%AD/"/>
    
    
      <category term="font" scheme="https://xiang578.com/tags/font/"/>
    
  </entry>
  
  <entry>
    <title>博客折腾记：使用 Travis CI 自动部署博客</title>
    <link href="https://xiang578.com/post/use-travis-ci-to-auto-build-blog.html"/>
    <id>https://xiang578.com/post/use-travis-ci-to-auto-build-blog.html</id>
    <published>2018-09-03T23:05:50.000Z</published>
    <updated>2019-12-02T02:24:36.172Z</updated>
    
    <content type="html"><![CDATA[<p>之前一周，都在接受公司的项目开发培训，了解公司的项目开发全流程。其中有一点是服务的稳定性。不知道为什么，前几天自己的博客崩溃了，输入域名只能看到 404 页面。当时以为是 Travis CI 的原因，所以进行了全面的一次排查。最终发现问题在 Github Pages 的 Custom domain 上。具体的问题表现是：通过 Travis CI 推送博客静态文件到仓库中的 master 后，下图框中的域名就会变成空的，导致无法访问。解决方法也很简单，在源文件的 source 目录下创建一个 CNAME 文件，写上你自己的域名。</p><figure><img src="/file/15358143289885.jpg" alt="-w768"><figcaption>-w768</figcaption></figure><h2 id="travis-ci">Travis CI</h2><p>其实看一眼就应该知道，我的博客是基于 hexo 搭建的，文件托管在 github 仓库中。不过，按照之前的设想博客应该在 Coding 中也有一份备份。后来由于一些原因，在利用 hexo 生成静态文件之后，自动推送到 Coding 上的命令不起作用。自己也没有时间去排查问题，所以最近访问速度有点慢。</p><p>传统的 hexo 博客更新过程是：在完成写作之后，利用命令行调用 <code>hexo g &amp;&amp; hexo d</code> 来生成静态博客文件以及并推送到远端的仓库中。这种方法会产生三个痛点： 1. 每一次修改源文件后都需要重新生成一边静态文件，当大量修改时，步骤就变得繁琐且无趣。 2. 生成文件依赖电脑中的 hexo 和 node.js 环境，不方便在外出时临时写或修改博客。 3. 博客源文件没有自动的备份功能，不符合安全原则。</p><p>Travis CI 是一种持续集成开发所使用的工具，在写作过程中引入他可以解决上面我提到的痛点。Travis CI 具体的含义我也不是很清楚，直接介绍我是怎么使用的。和大部分人一样，这个博客的静态文件保存在 github 的 xiang578.github.io 仓库 master 分支中。但是，我还创建了一个新的分支 hexo，用来保存博客源文件。每一次修改博客源文件之后，我不在本地生成静态文件，而是利用 git 命令，将所有的修改内容推送到仓库中的 hexo 分支。Travis CI 服务监听到新的 push 时，会根据你的配置将 git 仓库拉倒他的服务器上，编译源文件成为静态文件，并推送生成的文件到指定仓库的指定分支中。而且，如果编译静态文件失败，他也会通过邮件通知你结果。</p><figure><img src="/file/15359362837525.jpg" alt="编译成功截图"><figcaption>编译成功截图</figcaption></figure><h2 id="流程">流程</h2><ol type="1"><li>将 github 上存放静态博客源文件的仓库拉下来，利用 <code>git checkout -b hexo</code> 创建并进入新的分支，删除分支内所有的文件。</li><li>将博客源文件复制到第一步中的文件夹中。</li><li>添加一个 <code>.travis.yml</code> 文件，文件内容可以参考下一节 Travis-ci 配置文件。</li><li>https://travis-ci.org/ 提供免费的持续集成服务，可以通过 github 登入，直接选择需要管理相关的项目。</li><li>第一次将源文件上传到 github 时，可能会遇到问题。因为 themes/xxx 文件夹也是一个git仓库。可以利用 <code>git submodule add</code> 命令添加一个依赖，来解决这 个问题。</li></ol><h2 id="travis-ci-配置文件">Travis-ci 配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">language: node_js</span><br><span class="line">node_js:</span><br><span class="line">- 9.11.1</span><br><span class="line">cache:</span><br><span class="line">  directories:</span><br><span class="line">  - node_modules</span><br><span class="line">before_install:</span><br><span class="line">- export TZ=&apos;Asia/Shanghai&apos;</span><br><span class="line">- npm install hexo-cli -g</span><br><span class="line">install:</span><br><span class="line">- npm install</span><br><span class="line">script:</span><br><span class="line">- hexo clean</span><br><span class="line">- hexo generate</span><br><span class="line">after_script:</span><br><span class="line">  -  git clone https://$&#123;GH_REF&#125; .deploy_git  # GH_REF是最下面配置的仓库地址</span><br><span class="line">  - cd .deploy_git</span><br><span class="line">  - git checkout master</span><br><span class="line">  - cd ../</span><br><span class="line">  - mv .deploy_git/.git/ ./public/ </span><br><span class="line">  - cd ./public</span><br><span class="line">  - git config user.name &quot;xiang578&quot;</span><br><span class="line">  - git config user.email &quot;xiang578@foxmail.com&quot;</span><br><span class="line">  - git add .</span><br><span class="line">  # - git commit -m &quot;Deploy at $(date +&quot;%Y-%m-%d %T&quot;)&quot;</span><br><span class="line">  - git commit -m &quot;Travis CI Auto Builder at `date +&quot;%Y-%m-%d %H:%M&quot;`&quot;</span><br><span class="line">  # Github Pages</span><br><span class="line">  - git push --force --quiet &quot;https://$&#123;CI_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master </span><br><span class="line">  # Coding Pages</span><br><span class="line">  # - git push --force --quiet &quot;https://xiang578:$&#123;Coding_TOKEN&#125;@$&#123;CO_REF&#125;&quot; master:master</span><br><span class="line"></span><br><span class="line">branches:</span><br><span class="line">  only:</span><br><span class="line">  - hexo</span><br><span class="line"></span><br><span class="line">env:</span><br><span class="line"> global:</span><br><span class="line">   # Github Pages</span><br><span class="line">   - GH_REF: github.com/xiang578/xiang578.github.io</span><br><span class="line">   # Coding Pages</span><br><span class="line">   # - CO_REF: git.coding.net/xiang578/xiang578.git</span><br></pre></td></tr></table></figure><h2 id="hexo-两个错误">hexo 两个错误</h2><p>在这一次的过程中，又遇到了两个本地编译 hexo 的错误，一同记录一下。错误表现如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">ERROR Plugin load failed: hexo-renderer-sass</span><br><span class="line">Error: Cannot find module 'node-sass'</span><br><span class="line">    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:581:15)</span><br><span class="line">    at Function.Module._load (internal/modules/cjs/loader.js:507:25)</span><br><span class="line">    at Module.require (internal/modules/cjs/loader.js:637:17)</span><br><span class="line">    at require (internal/modules/cjs/helpers.js:20:18)</span><br><span class="line">    at Object.&lt;anonymous&gt; (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo-renderer-sass/lib/renderer.js:4:12)</span><br><span class="line">    at Module._compile (internal/modules/cjs/loader.js:689:30)</span><br><span class="line">    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)</span><br><span class="line">    at Module.load (internal/modules/cjs/loader.js:599:32)</span><br><span class="line">    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)</span><br><span class="line">    at Function.Module._load (internal/modules/cjs/loader.js:530:3)</span><br><span class="line">    at Module.require (internal/modules/cjs/loader.js:637:17)</span><br><span class="line">    at require (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo/lib/hexo/index.js:219:21)</span><br><span class="line">    at /Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo-renderer-sass/index.js:4:20</span><br><span class="line">    at fs.readFile.then.script (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo/lib/hexo/index.js:232:12)</span><br><span class="line">    at tryCatcher (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/util.js:16:23)</span><br><span class="line">    at Promise._settlePromiseFromHandler (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:512:31)</span><br><span class="line">    at Promise._settlePromise (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:569:18)</span><br><span class="line">    at Promise._settlePromise0 (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:614:10)</span><br><span class="line">    at Promise._settlePromises (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:693:18)</span><br><span class="line">    at Promise._fulfill (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:638:18)</span><br><span class="line">    at Promise._resolveCallback (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:432:57)</span><br><span class="line">    at Promise._settlePromiseFromHandler (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:524:17)</span><br><span class="line">ERROR Plugin load failed: hexo-renderer-scss</span><br><span class="line">Error: Node Sass does not yet support your current environment: OS X 64-bit with Unsupported runtime (64)</span><br><span class="line">For more information on which environments are supported please see:</span><br><span class="line">https://github.com/sass/node-sass/releases/tag/v4.8.3</span><br><span class="line">    at module.exports (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo-renderer-scss/node_modules/node-sass/lib/binding.js:13:13)</span><br><span class="line">    at Object.&lt;anonymous&gt; (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo-renderer-scss/node_modules/node-sass/lib/index.js:14:35)</span><br><span class="line">    at Module._compile (internal/modules/cjs/loader.js:689:30)</span><br><span class="line">    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)</span><br><span class="line">    at Module.load (internal/modules/cjs/loader.js:599:32)</span><br><span class="line">    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)</span><br><span class="line">    at Function.Module._load (internal/modules/cjs/loader.js:530:3)</span><br><span class="line">    at Module.require (internal/modules/cjs/loader.js:637:17)</span><br><span class="line">    at require (internal/modules/cjs/helpers.js:20:18)</span><br><span class="line">    at Object.&lt;anonymous&gt; (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo-renderer-scss/lib/renderer.js:1:76)</span><br><span class="line">    at Module._compile (internal/modules/cjs/loader.js:689:30)</span><br><span class="line">    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)</span><br><span class="line">    at Module.load (internal/modules/cjs/loader.js:599:32)</span><br><span class="line">    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)</span><br><span class="line">    at Function.Module._load (internal/modules/cjs/loader.js:530:3)</span><br><span class="line">    at Module.require (internal/modules/cjs/loader.js:637:17)</span><br><span class="line">    at require (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo/lib/hexo/index.js:219:21)</span><br><span class="line">    at /Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo-renderer-scss/index.js:1:81</span><br><span class="line">    at fs.readFile.then.script (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/hexo/lib/hexo/index.js:232:12)</span><br><span class="line">    at tryCatcher (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/util.js:16:23)</span><br><span class="line">    at Promise._settlePromiseFromHandler (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:512:31)</span><br><span class="line">    at Promise._settlePromise (/Users/didi/Documents/Personal/xiang578.github.io/node_modules/bluebird/js/release/promise.js:569:18)</span><br></pre></td></tr></table></figure><p>大概总结是下载两个插件时，出现错误。网上的建议是修改 npm 的源地址为淘宝的镜像，并且重新下载这两个包。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo npm config set registry https://registry.npm.taobao.org</span><br><span class="line">npm install hexo-renderer-sass --save</span><br><span class="line">npm install hexo-renderer-scss --save</span><br></pre></td></tr></table></figure><h2 id="reference">Reference</h2><ul><li><a href="https://blog.csdn.net/qq_23079443/article/details/79015225" target="_blank" rel="noopener">用TravisCI持续集成自动部署Hexo博客的个人实践 - CSDN博客</a></li><li><a href="https://segmentfault.com/a/1190000009928515" target="_blank" rel="noopener">关于 git-submodule 的一些基本操作 - 个人文章 - SegmentFault 思否</a></li><li><a href="https://www.v2ex.com/t/260832" target="_blank" rel="noopener">安装 npm install hexo-renderer-sass --save 出错，有什么办法没 - V2EX</a></li><li><a href="https://blog.csdn.net/xs20691718/article/details/81873921" target="_blank" rel="noopener">hexo 发布之后 gitpage 自定义域名失效 - CSDN博客</a></li></ul><h2 id="changelog">ChangeLog</h2><ul><li>180904：完成初稿</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前一周，都在接受公司的项目开发培训，了解公司的项目开发全流程。其中有一点是服务的稳定性。不知道为什么，前几天自己的博客崩溃了，输入域名只能看到 404 页面。当时以为是 Travis CI 的原因，所以进行了全面的一次排查。最终发现问题在 Github Pages 的 C
      
    
    </summary>
    
      <category term="站务" scheme="https://xiang578.com/categories/%E7%AB%99%E5%8A%A1/"/>
    
    
      <category term="blog" scheme="https://xiang578.com/tags/blog/"/>
    
      <category term="hexo" scheme="https://xiang578.com/tags/hexo/"/>
    
      <category term="github" scheme="https://xiang578.com/tags/github/"/>
    
      <category term="travisci" scheme="https://xiang578.com/tags/travisci/"/>
    
  </entry>
  
</feed>
